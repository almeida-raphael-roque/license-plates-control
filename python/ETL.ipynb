{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf422456",
   "metadata": {},
   "source": [
    "# EXTRACT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54790159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import awswrangler as awr\n",
    "import logging\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Exibe mensagens a partir de INFO\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[\n",
    "        logging.StreamHandler()  # Garante logs no console\n",
    "    ]\n",
    ")\n",
    "\n",
    "logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "logging.info('\\n Executando Rotina: Movimentação de Placas')\n",
    "\n",
    "class Extract:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.path = r\"C:\\Users\\raphael.almeida\\Documents\\Processos\\placas_movimentacoes\"\n",
    "\n",
    "    def extract_all_ativacoes(self):\n",
    "\n",
    "        try:\n",
    "            dir_query = os.path.join(self.path, 'sql', 'all_boards_ATIVOS.sql')\n",
    "            with open(dir_query, 'r') as file:\n",
    "                query = file.read()\n",
    "            df_ativacoes = awr.athena.read_sql_query(query, database='silver')\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info('\\n Consulta de ativações extraída com sucesso!')\n",
    "            return df_ativacoes\n",
    "        except Exception as e:\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'\\n Falha ao extrair a consulta de ativações: {e}')\n",
    "            return None\n",
    "\n",
    "    def extract_all_cancelamentos(self):\n",
    "\n",
    "        try:\n",
    "            dir_query = os.path.join(self.path, 'sql', 'all_boards_CANCELADOS.sql')\n",
    "            with open(dir_query, 'r') as file:\n",
    "                query = file.read()\n",
    "            df_cancelamentos = awr.athena.read_sql_query(query, database='silver')\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info('\\n Consulta de cancelamentos extraída com sucesso!')\n",
    "            return df_cancelamentos\n",
    "        except Exception as e:\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'\\n Falha ao extrair a consulta de cancelamentos: {e}')\n",
    "            return None\n",
    "\n",
    "    def extract_conf_boards(self):\n",
    "\n",
    "        try:\n",
    "\n",
    "            dir_query = os.path.join(self.path,'sql', 'listagem_mestra.sql')\n",
    "\n",
    "            with open(dir_query, 'r') as file:\n",
    "                query = file.read()\n",
    "\n",
    "            df_conferencia = awr.athena.read_sql_query(query, database='silver')\n",
    "        \n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info('\\n Consulta de dados históricos realizada com sucesso!')\n",
    "\n",
    "            return df_conferencia\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'\\n Falha ao extrair consulta de dados históricos: {e}')\n",
    "\n",
    "\n",
    "\n",
    "extract = Extract()\n",
    "df_ativacoes = extract.extract_all_ativacoes()\n",
    "df_cancelamentos = extract.extract_all_cancelamentos()\n",
    "df_conf = extract.extract_conf_boards()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839be64a",
   "metadata": {},
   "source": [
    "# TRANSFORM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1794c277",
   "metadata": {},
   "source": [
    "board_status_treatment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f270cd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANDO MÓDULOS E PACOTES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "class Transform:\n",
    "        \n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    # CRIANDO FUNÇÃO QUE IRÁ APLICAR O TRATAMENTO DE STATUS DAS PLACAS ATIVADAS\n",
    "    def board_status_treatment(df, df_ontem, df_conf, status_filter_list):\n",
    "\n",
    "        try:\n",
    "            status_filter_list = ['CANCELADO', 'CANCELADA', 'FINALIZADO', 'FINALIZADA', 'NAO RENOVADO']\n",
    "\n",
    "            if not df.empty:\n",
    "                logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "                logging.info(df.shape)\n",
    "                row_count = 0\n",
    "                for idx, row in df.iterrows():\n",
    "                    row_count += 1\n",
    "                    df_comp_ontem = df_ontem[df_ontem['chassi'] == row['chassi']]\n",
    "                    df_comp_conf = df_conf[(df_conf['chassi'] == row['chassi']) & (df_conf['beneficio'] == row['beneficio'])].sort_values(by='data_ativacao', ascending=False)\n",
    "\n",
    "                    if not df_comp_ontem.empty:                                        \n",
    "                                if df_comp_ontem['empresa']!=row['empresa']:\n",
    "                                    df.at[idx, 'status_beneficio'] = 'MIGRAÇÃO'\n",
    "                                    df.at[idx, 'migration_from'] = 'NULL'\n",
    "                                else:\n",
    "                                    df.at[idx, 'status_beneficio'] = 'ATIVO'\n",
    "                                    df.at[idx, 'migration_from'] = 'NULL'                     \n",
    "                    else:\n",
    "                        hist_datas_ativacao = sorted(df_comp_conf['data_ativacao_beneficio'].dropna().drop_duplicates().unique())                    \n",
    "                        if len(hist_datas_ativacao) > 1:\n",
    "                            penultimo_registro_data = hist_datas_ativacao[-2]\n",
    "                            verification_penultima_row = df_comp_conf.loc[df_comp_conf['data_ativacao_beneficio'] == penultimo_registro_data]\n",
    "                            \n",
    "                            if verification_penultima_row['status_beneficio'].values[0] not in status_filter_list:\n",
    "                                if verification_penultima_row['empresa'].values[0] != row['empresa']:\n",
    "                                    df.at[idx, 'status_beneficio'] = 'MIGRAÇÃO' #EM ALGUM MOMENTO ELA ESTAVA COMO ATIVA NA OUTRA EMPRESA, NÃO FOI CANCELADA, MAS TAMBÉM NÃO ESTAVA ATIVA\n",
    "                                    df.at[idx, 'migration_from'] = verification_penultima_row['empresa'].values[0]\n",
    "                                else:\n",
    "                                    df.at[idx, 'status_beneficio'] = 'RENOVAÇÃO' #NÃO TINHA STATUS DE CANCELAMENTO NA EMPRESA, MAS TAMBÉM NÃO ESTAVA ATIVA\n",
    "                                    df.at[idx, 'migration_from'] = 'NULL'\n",
    "                            else:\n",
    "                                    df.at[idx, 'status_beneficio'] = 'REATIVAÇÃO'\n",
    "                                    df.at[idx, 'migration_from'] = 'NULL'\n",
    "                                    \n",
    "                        else:\n",
    "                            df.at[idx, 'status_beneficio'] = 'NOVO'\n",
    "                            df.at[idx, 'migration_from'] = 'NULL'\n",
    "\n",
    "                logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "                logging.info(f'Total de linhas processadas: {row_count}')\n",
    "\n",
    "            else:\n",
    "                logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "                logging.info('Nenhum registro de ativações para tratamento de dados. Dataframe vazio!')\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'Falha no tratamento de status das placas ativadas. Revise o código: {e}')\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c27da3a",
   "metadata": {},
   "source": [
    "transform "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93b6069b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANDO MÓDULOS E PACOTES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import logging\n",
    "\n",
    "\n",
    "class Transform:\n",
    "        \n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def transforming_files(self):\n",
    "\n",
    "#DEFININDO DATAFRAMES VAZIOS \n",
    "        try:\n",
    "\n",
    "            df_final_ativacoes = pd.DataFrame()\n",
    "            df_final_cancelamentos = pd.DataFrame()\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info('Falha ao definir dataframes.')\n",
    "\n",
    "#TRANSFORMANDO DF_ATIV E SEGMENTANDO POR EMPRESA\n",
    "        try:\n",
    "            df_ativ_all_boards=df_ativacoes\n",
    "            df_final_cancelamentos=df_cancelamentos\n",
    "            \n",
    "            #extract = Extract()\n",
    "            #df_final_cancelamentos = extract.extract_all_cancelamentos()\n",
    "            #df_ativ_all_boards = extract.extract_all_ativacoes()\n",
    "\n",
    "            df_ativ_all_boards['data_ativacao_beneficio'] = pd.to_datetime(df_ativ_all_boards['data_ativacao_beneficio']).dt.date\n",
    "                        \n",
    "            df_ativ_all_boards['beneficio'] = df_ativ_all_boards['beneficio'].replace('REPARAÇÃO OU REPOSIÇÃO DO VEÍCULO', 'CASCO (VEÍCULO)').replace('REPARAÇÃO OU REPOSIÇÃO DO (SEMI)REBOQUE', 'CASCO (R/SR)').replace('REPARAÇÃO OU REPOSIÇÃO DO COMPLEMENTO', 'CASCO (COMPLEMENTO)')\n",
    "            \n",
    "            df_ativ_viavante = df_ativ_all_boards[df_ativ_all_boards['empresa'] == 'Viavante']\n",
    "            df_ativ_stcoop = df_ativ_all_boards[df_ativ_all_boards['empresa'] == 'Stcoop']\n",
    "            df_ativ_segtruck = df_ativ_all_boards[df_ativ_all_boards['empresa'] == 'Segtruck']\n",
    "            df_ativ_tag = df_ativ_all_boards[df_ativ_all_boards['empresa'] == 'Tag']\n",
    "\n",
    "            df_final_cancelamentos = df_final_cancelamentos\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')  \n",
    "            logging.info(f'Falha ao realizar a segmentação dos dataframes: {e}')\n",
    "\n",
    "# SELECIONANDO APENAS AS ATIVAÇÕES CORRESPONDENTES AOS BENEFICIOS 'CASCO' / 'TERCEIRO' POR UM REGEX PADRÃO\n",
    "        try:\n",
    "            ids_beneficios_segtruck = [2, 3, 4, 7, 24, 25, 26, 29]\n",
    "            ids_beneficios_stcoop = [24, 25, 26, 29]\n",
    "            ids_beneficios_viavante = [40, 41, 42, 45]\n",
    "            ids_beneficios_tag = [2, 3, 4, 7, 24, 25, 26, 29, 34, 35, 36, 37, 38, 39]\n",
    "\n",
    "            df_ativ_viavante = df_ativ_viavante.loc[df_ativ_viavante['id_beneficio'].isin(ids_beneficios_viavante)]\n",
    "            df_ativ_stcoop = df_ativ_stcoop.loc[df_ativ_stcoop['id_beneficio'].isin(ids_beneficios_stcoop)]\n",
    "            df_ativ_segtruck = df_ativ_segtruck.loc[df_ativ_segtruck['id_beneficio'].isin(ids_beneficios_segtruck)]\n",
    "            df_ativ_tag = df_ativ_tag.loc[df_ativ_tag['id_beneficio'].isin(ids_beneficios_tag)]\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')  \n",
    "            logging.info(f'Falha ao padronizar nomenclaturas referente aos beneficios pré-estabelecidos: {e}')\n",
    "\n",
    "# CONCATENANDO E CRIANDO COLUNA DE MIGRAÇÃO (MIGRATION_FROM) \n",
    "        try:\n",
    "\n",
    "            df_final_ativacoes = pd.concat([df_ativ_viavante, df_ativ_stcoop, df_ativ_segtruck, df_ativ_tag])\n",
    "\n",
    "            if not df_final_ativacoes.empty:\n",
    "                df_final_ativacoes['migration_from'] = np.nan\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'Falha na criação da coluna de migração e concatenação de dataframes: {e}')\n",
    "\n",
    "    # DEFININDO COLUNAS QUE SERÃO UTILIZADAS NO DATAFRAME FINAL\n",
    "        try:\n",
    "           \n",
    "            df_final_ativacoes = df_final_ativacoes[[\n",
    "                'placa', 'chassi', 'id_placa', 'id_veiculo', 'id_carroceria', 'matricula', 'conjunto', 'unidade', 'consultor', 'status_beneficio', \n",
    "                'cliente', 'data_registro', 'data_ativacao_beneficio', 'suporte', 'data_filtro', 'empresa', 'migration_from'\n",
    "            ]]\n",
    "\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'Processo de seleção de colunas realizado com sucesso!')\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'Falha ao definir colunas: {e}')\n",
    "\n",
    "    # RETIRANDO DUPLICATAS\n",
    "        try:\n",
    "            df_final_ativacoes = df_final_ativacoes.drop_duplicates(subset=['chassi'])\n",
    "\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'Duplicatas retiradas com sucesso.')\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'Falha ao retirar duplicatas. Revise o código: {e}')\n",
    "\n",
    "# TRATANDO DADOS NULOS NOS DATAFRAMES\n",
    "        try:\n",
    "            df_final_ativacoes['placa'] = df_final_ativacoes['placa'].fillna('SEM-PLACA')\n",
    "            df_final_ativacoes['chassi'] = df_final_ativacoes['chassi'].fillna('NULL')\n",
    "            df_final_ativacoes['id_placa'] = df_final_ativacoes['id_placa'].fillna(0)\n",
    "            df_final_ativacoes['id_veiculo'] = df_final_ativacoes['id_veiculo'].fillna(0)\n",
    "            df_final_ativacoes['id_carroceria'] = df_final_ativacoes['id_carroceria'].fillna(0)\n",
    "            df_final_ativacoes['matricula'] = df_final_ativacoes['matricula'].fillna(0)\n",
    "            df_final_ativacoes['conjunto'] = df_final_ativacoes['conjunto'].fillna(0)\n",
    "            df_final_ativacoes['unidade'] = df_final_ativacoes['unidade'].fillna('NULL')\n",
    "            df_final_ativacoes['consultor'] = df_final_ativacoes['consultor'].fillna('NULL')\n",
    "            df_final_ativacoes['status_beneficio'] = df_final_ativacoes['status_beneficio'].fillna('NULL')\n",
    "            df_final_ativacoes['cliente'] = df_final_ativacoes['cliente'].fillna('NULL')\n",
    "            df_final_ativacoes['data_registro'] = df_final_ativacoes['data_registro'].fillna(pd.Timestamp('1900-01-01'))\n",
    "            df_final_ativacoes['data_ativacao_beneficio'] = df_final_ativacoes['data_ativacao_beneficio'].fillna(pd.Timestamp('1900-01-01'))\n",
    "            df_final_ativacoes['suporte'] = df_final_ativacoes['suporte'].fillna('NULL')\n",
    "            df_final_ativacoes['data_filtro'] = df_final_ativacoes['data_filtro'].fillna(pd.Timestamp('1900-01-01'))\n",
    "            df_final_ativacoes['empresa'] = df_final_ativacoes['empresa'].fillna('NULL')\n",
    "            df_final_ativacoes['migration_from'] = df_final_ativacoes['migration_from'].fillna('NULL')\n",
    "\n",
    "            df_final_cancelamentos['placa'] = df_final_cancelamentos['placa'].fillna('SEM-PLACA')\n",
    "            df_final_cancelamentos['chassi'] = df_final_cancelamentos['chassi'].fillna('NULL')\n",
    "            df_final_cancelamentos['id_placa'] = df_final_cancelamentos['id_placa'].fillna(0)\n",
    "            df_final_cancelamentos['id_veiculo'] = df_final_cancelamentos['id_veiculo'].fillna(0)\n",
    "            df_final_cancelamentos['id_carroceria'] = df_final_cancelamentos['id_carroceria'].fillna(0)\n",
    "            df_final_cancelamentos['matricula'] = df_final_cancelamentos['matricula'].fillna(0)\n",
    "            df_final_cancelamentos['conjunto'] = df_final_cancelamentos['conjunto'].fillna(0)\n",
    "            df_final_cancelamentos['unidade'] = df_final_cancelamentos['unidade'].fillna('NULL')\n",
    "            df_final_cancelamentos['status'] = df_final_cancelamentos['status'].fillna('NULL')\n",
    "            df_final_cancelamentos['cliente'] = df_final_cancelamentos['cliente'].fillna('NULL')\n",
    "            df_final_cancelamentos['data'] = df_final_cancelamentos['data'].fillna(pd.Timestamp('1900-01-01'))\n",
    "            df_final_cancelamentos['data_cancelamento'] = df_final_cancelamentos['data_cancelamento'].fillna(pd.Timestamp('1900-01-01'))\n",
    "            df_final_cancelamentos['usuario_cancelamento'] = df_final_cancelamentos['usuario_cancelamento'].fillna('NULL')\n",
    "            df_final_cancelamentos['data_filtro'] = df_final_cancelamentos['data_filtro'].fillna(pd.Timestamp('1900-01-01'))\n",
    "            df_final_cancelamentos['empresa'] = df_final_cancelamentos['empresa'].fillna('NULL')\n",
    "            df_final_cancelamentos['migracao'] = df_final_cancelamentos['migracao'].fillna('NULL')\n",
    "            df_final_cancelamentos['renegociacao'] = df_final_cancelamentos['renegociacao'].fillna('NULL')\n",
    "            df_final_cancelamentos['data_substituicao'] = df_final_cancelamentos['data_substituicao'].fillna(pd.Timestamp('1900-01-01'))\n",
    "\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info('\\n Processo de Transformacao de Dados concluido com sucesso!')\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'Falha ao realizar tratamento de dados: {e}')\n",
    "     \n",
    "            return df_final_ativacoes, df_final_cancelamentos\n",
    "    \n",
    "transform = Transform()\n",
    "df_final_ativacoes, df_final_cancelamentos = transform.transforming_files()\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e3eaa2",
   "metadata": {},
   "source": [
    "board_status_treatment2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf72652",
   "metadata": {},
   "source": [
    "declaring variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed782df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "536cf09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANDO MÓDULOS E PACOTES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "import awswrangler as awr\n",
    "\n",
    "xlsx_ontem = r\"C:\\Users\\raphael.almeida\\Documents\\Processos\\placas_movimentacoes\\placas_movimentacoes_ontem.xlsx\"\n",
    "xlsx = r\"C:\\Users\\raphael.almeida\\Documents\\Processos\\placas_movimentacoes\\placas_movimentacoes.xlsx\"\n",
    "\n",
    "df_ontem = pd.read_excel(xlsx_ontem, engine='openpyxl', sheet_name= 'ATIVAÇÕES')\n",
    "df = pd.read_excel(xlsx, engine='openpyxl')\n",
    "status_filter_list = ['CANCELADO', 'CANCELADA', 'FINALIZADO', 'FINALIZADA', 'NAO RENOVADO']\n",
    "\n",
    "path = r\"C:\\Users\\raphael.almeida\\Documents\\Processos\\placas_movimentacoes\"\n",
    "dir_query = os.path.join(path,'sql', 'listagem_mestra.sql')\n",
    "\n",
    "with open(dir_query, 'r') as file:\n",
    "    query = file.read()\n",
    "\n",
    "df_conferencia = awr.athena.read_sql_query(query, database='silver')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0e86adbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32908\n",
      "33250\n"
     ]
    }
   ],
   "source": [
    "print(df.shape[0])\n",
    "print(df_ontem.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2f69a905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "32908\n"
     ]
    }
   ],
   "source": [
    "df_novos = df[df['status_beneficio']=='NOVO']\n",
    "df_ativos = df[df['status_beneficio']=='ATIVO']\n",
    "\n",
    "print(df_novos.shape[0])\n",
    "print(df_ativos.shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "06509cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir df_cancelados: existiam ontem e não existem hoje\n",
    "set_hoje = set(df['chassi'].dropna().unique()) if 'chassi' in df.columns else set()\n",
    "\n",
    "if 'chassi' in df_ontem.columns:\n",
    "    cancelados_mask = ~df_ontem['chassi'].isin(set_hoje)\n",
    "    df_cancelados = df_ontem.loc[cancelados_mask].copy()\n",
    "else:\n",
    "    df_cancelados = pd.DataFrame(columns=df_ontem.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "766360cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "448"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cancelados = pd.DataFrame(df_cancelados)\n",
    "df_cancelados.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a63cfa5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m xlsx_cancelation_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mraphael.almeida\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mProcessos\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mplacas_movimentacoes\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdf_cancelamentos.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m df_cancelamentos \u001b[38;5;241m=\u001b[39m df_cancelamentos\u001b[38;5;241m.\u001b[39mto_excel(xlsx_cancelation_path, engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopenpyxl\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mdf_cancelamentos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "xlsx_cancelation_path = r\"C:\\Users\\raphael.almeida\\Documents\\Processos\\placas_movimentacoes\\df_cancelamentos.xlsx\"\n",
    "df_cancelamentos = df_cancelamentos.to_excel(xlsx_cancelation_path, engine='openpyxl', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5af9d445",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlsx_cancel_path = r\"C:\\Users\\raphael.almeida\\Documents\\Processos\\placas_movimentacoes\\df_cancelados.xlsx\"\n",
    "df_cancelados = df_cancelados.to_excel(xlsx_cancel_path, engine='openpyxl', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e521908e",
   "metadata": {},
   "source": [
    "first function: NEW / ACTIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4ec8688b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(         placa             chassi  id_placa  id_veiculo  id_carroceria  \\\n",
       " 0      MGC1B11  9BVN4DAA0YE672083  17322444    17322444              0   \n",
       " 1      MGA0I88  9BST4X2A043550744  17322241    17322241              0   \n",
       " 2      MFJ8H57  9BFVCE1N3ABB42605  17322663    17322663              0   \n",
       " 3      MFE4B62  9BSR4X2A053564937  17322315    17322315              0   \n",
       " 4      BEX9G24  9ADG0942MMM477102     27469           0          27469   \n",
       " ...        ...                ...       ...         ...            ...   \n",
       " 32903  QAB1870  94BL0262KKR004389      3485           0           3485   \n",
       " 32904  MHB9F69  955L14639AS299249      3652           0           3652   \n",
       " 32905  AXV7H35  9EP081630E1001931      3198           0           3198   \n",
       " 32906  AJW6D00  955L1463EES359870      3194           0           3194   \n",
       " 32907  ESU7G77  9BSP4X200C3805546    339080      339080              0   \n",
       " \n",
       "        matricula  conjunto                                            unidade  \\\n",
       " 0           5175     16639                                OPENTRUCK CORRETORA   \n",
       " 1           5175     16639                                OPENTRUCK CORRETORA   \n",
       " 2           5175     16639                                OPENTRUCK CORRETORA   \n",
       " 3           5175     16639                                OPENTRUCK CORRETORA   \n",
       " 4           1023     20469                                   UNIDADE LONDRINA   \n",
       " ...          ...       ...                                                ...   \n",
       " 32903        975      1074                               UNIDADE CAMPO GRANDE   \n",
       " 32904        993      1116          MICRO A - R A SERVICOS & CONSULTORIA LTDA   \n",
       " 32905       1007      1134  MICRO B - T.V PASQUINI SERVICOS ADMINISTRATIVO...   \n",
       " 32906       1007      1134  MICRO B - T.V PASQUINI SERVICOS ADMINISTRATIVO...   \n",
       " 32907       1039      1912            CO.CO - MD REPRESENTACAO COMERCIAL LTDA   \n",
       " \n",
       "                                   consultor status_beneficio  \\\n",
       " 0                             Gilvana Daros            ATIVO   \n",
       " 1                             Gilvana Daros            ATIVO   \n",
       " 2                             Gilvana Daros            ATIVO   \n",
       " 3                             Gilvana Daros            ATIVO   \n",
       " 4            Daiane Cristina Veiga da Silva            ATIVO   \n",
       " ...                                     ...              ...   \n",
       " 32903               Icaro Gomes De Oliveira            ATIVO   \n",
       " 32904                       Rodrigo Almeida            ATIVO   \n",
       " 32905                   MF - TIAGO PASQUINI            ATIVO   \n",
       " 32906                   MF - TIAGO PASQUINI            ATIVO   \n",
       " 32907  CS - MD REPRESENTACAO COMERCIAL LTDA             NOVO   \n",
       " \n",
       "                                                  cliente data_registro  \\\n",
       " 0      APROSSIL - ASSOCIACAO DE PROPRIETARIOS DE CAMI...    2025-05-20   \n",
       " 1      APROSSIL - ASSOCIACAO DE PROPRIETARIOS DE CAMI...    2025-05-20   \n",
       " 2      APROSSIL - ASSOCIACAO DE PROPRIETARIOS DE CAMI...    2025-05-20   \n",
       " 3      APROSSIL - ASSOCIACAO DE PROPRIETARIOS DE CAMI...    2025-05-20   \n",
       " 4                         TRANSPORTADORA SEMCHECHEM LTDA    2025-07-14   \n",
       " ...                                                  ...           ...   \n",
       " 32903                            CEREALISTA ANZIBAS LTDA    2025-08-18   \n",
       " 32904            RAPIDO EXPRESSO EVOLOG TRANSPORTES LTDA    2025-08-18   \n",
       " 32905                        PADROEIRA BR. LOCAÇÕES LTDA    2025-08-18   \n",
       " 32906                        PADROEIRA BR. LOCAÇÕES LTDA    2025-08-18   \n",
       " 32907                         M V DOS SANTOS TRANSPORTES    2025-08-26   \n",
       " \n",
       "       data_ativacao_beneficio                      suporte data_filtro  \\\n",
       " 0                  2025-06-02  Lucas Belmiro Mendes Santos  2025-08-27   \n",
       " 1                  2025-06-02  Lucas Belmiro Mendes Santos  2025-08-27   \n",
       " 2                  2025-06-02  Lucas Belmiro Mendes Santos  2025-08-27   \n",
       " 3                  2025-06-02  Lucas Belmiro Mendes Santos  2025-08-27   \n",
       " 4                  2025-07-14  Lucas Belmiro Mendes Santos  2025-08-27   \n",
       " ...                       ...                          ...         ...   \n",
       " 32903              2025-08-19  Diego Alejandro Cortes Moya  2025-08-27   \n",
       " 32904              2025-08-18  Lucas Belmiro Mendes Santos  2025-08-27   \n",
       " 32905              2025-08-19  Lucas Belmiro Mendes Santos  2025-08-27   \n",
       " 32906              2025-08-19  Lucas Belmiro Mendes Santos  2025-08-27   \n",
       " 32907              2025-08-26             Lucas Lobo Didur  2025-08-27   \n",
       " \n",
       "         empresa  migration_from  \n",
       " 0      Viavante             NaN  \n",
       " 1      Viavante             NaN  \n",
       " 2      Viavante             NaN  \n",
       " 3      Viavante             NaN  \n",
       " 4      Viavante             NaN  \n",
       " ...         ...             ...  \n",
       " 32903       Tag             NaN  \n",
       " 32904       Tag             NaN  \n",
       " 32905       Tag             NaN  \n",
       " 32906       Tag             NaN  \n",
       " 32907       Tag             NaN  \n",
       " \n",
       " [32908 rows x 17 columns],\n",
       "          placa             chassi  id_placa  id_veiculo  id_carroceria  \\\n",
       " 0      JRG9B48  9BVAS02CX8E739021     57900       57900              0   \n",
       " 1      QOY8J68  9BVRG40D3KE858532    140755      140755              0   \n",
       " 2      ATR5I55  9ADB0602BBM325056     18944           0          18944   \n",
       " 3      ANL1A41  94BB084356R004137     72056           0          72056   \n",
       " 4      ASU5C66  9BVAS02C2AE759222     63583       63583              0   \n",
       " ...        ...                ...       ...         ...            ...   \n",
       " 33245  RLD7J46  9BM963403MB223003      1577        1577              0   \n",
       " 33246  NIZ0J97  9ADV079288M273218      3399           0           3399   \n",
       " 33247  STY2G97  97VCAB092R1004966      3727           0           3727   \n",
       " 33248  SPC0E67  9ADG0942PPM524751       931           0            931   \n",
       " 33249  QMW5H78  95388XZZ8JE800230    286877      286877              0   \n",
       " \n",
       "        matricula  conjunto                                            unidade  \\\n",
       " 0          45879    140071                                    UNIDADE MARINGÁ   \n",
       " 1          45879    140002                                    UNIDADE MARINGÁ   \n",
       " 2          45879    139931                                    UNIDADE MARINGÁ   \n",
       " 3          45879    139931                                    UNIDADE MARINGÁ   \n",
       " 4          45879    139931                                    UNIDADE MARINGÁ   \n",
       " ...          ...       ...                                                ...   \n",
       " 33245        787       867  FRANQUEADO - LEAO DE JUDA ADMINISTRACOES & PAR...   \n",
       " 33246        870       948                                    REINEHR SEGUROS   \n",
       " 33247       1230      1444    FRANQUEADO - J MAGALHAES VENDAS E SERVICOS LTDA   \n",
       " 33248       1241      1458                                      UNIDADE SINOP   \n",
       " 33249       1295      1519                             MUNDO SEGURO CORRETORA   \n",
       " \n",
       "                                     consultor status_beneficio  \\\n",
       " 0                                 Icaro Gomes            ATIVO   \n",
       " 1                                 Icaro Gomes            ATIVO   \n",
       " 2                                 Icaro Gomes            ATIVO   \n",
       " 3                                 Icaro Gomes            ATIVO   \n",
       " 4                                 Icaro Gomes            ATIVO   \n",
       " ...                                       ...              ...   \n",
       " 33245  Leao de Juda Jefferson Elyeser Neumann             NOVO   \n",
       " 33246                         Adriano Reinehr             NOVO   \n",
       " 33247             Franqueado - José Magalhães             NOVO   \n",
       " 33248       Queila De Camargo Reis Dos Santos             NOVO   \n",
       " 33249          Joao Paulo de Oliveira Barbosa             NOVO   \n",
       " \n",
       "                                                cliente data_registro  \\\n",
       " 0                                 AVANTE AVIARIOS LTDA    2024-11-14   \n",
       " 1                                 AVANTE AVIARIOS LTDA    2024-10-11   \n",
       " 2                                 AVANTE AVIARIOS LTDA    2024-08-30   \n",
       " 3                                 AVANTE AVIARIOS LTDA    2024-08-30   \n",
       " 4                                 AVANTE AVIARIOS LTDA    2024-08-30   \n",
       " ...                                                ...           ...   \n",
       " 33245  TRANSPERSIKE TRANSPORTE E AGENCIAMENTO DE CARGA    2025-08-14   \n",
       " 33246                       CONFIANCA TRANSPORTES LTDA    2025-08-15   \n",
       " 33247                 MONNICLEY RODRIGUES DE LIMA LTDA    2025-08-20   \n",
       " 33248                      TRANSPORTADORA KORINGA LTDA    2025-08-21   \n",
       " 33249                   IRMAOS MM TRANSPORTES LIMITADA    2025-08-21   \n",
       " \n",
       "       data_ativacao_beneficio                     suporte data_filtro  \\\n",
       " 0                  2024-11-16  VICTOR GABRIEL GOMES PICÃO  2025-08-26   \n",
       " 1                  2024-10-13             Luciana Pusebon  2025-08-26   \n",
       " 2                  2024-08-31    João Paulo Ribeiro Pinto  2025-08-26   \n",
       " 3                  2024-08-31    João Paulo Ribeiro Pinto  2025-08-26   \n",
       " 4                  2024-08-31    João Paulo Ribeiro Pinto  2025-08-26   \n",
       " ...                       ...                         ...         ...   \n",
       " 33245              2025-08-25    João Paulo Ribeiro Pinto  2025-08-26   \n",
       " 33246              2025-08-25    João Paulo Ribeiro Pinto  2025-08-26   \n",
       " 33247              2025-08-25            Lucas Lobo Didur  2025-08-26   \n",
       " 33248              2025-08-25            Lucas Lobo Didur  2025-08-26   \n",
       " 33249              2025-08-25             Luciana Pusebon  2025-08-26   \n",
       " \n",
       "         empresa migration_from  \n",
       " 0      Segtruck            NaN  \n",
       " 1      Segtruck            NaN  \n",
       " 2      Segtruck            NaN  \n",
       " 3      Segtruck            NaN  \n",
       " 4      Segtruck            NaN  \n",
       " ...         ...            ...  \n",
       " 33245       Tag            NaN  \n",
       " 33246       Tag            NaN  \n",
       " 33247       Tag            NaN  \n",
       " 33248       Tag            NaN  \n",
       " 33249       Tag            NaN  \n",
       " \n",
       " [33250 rows x 17 columns])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def process(df, df_ontem):\n",
    "    # Normalizar chassi em ambos os dataframes\n",
    "    for d in (df, df_ontem):\n",
    "        if 'chassi' in d.columns:\n",
    "            d['chassi'] = d['chassi'].astype(str).str.strip().str.upper()\n",
    "\n",
    "    # Conjuntos para comparação\n",
    "    set_ontem = set(df_ontem['chassi'].dropna().unique()) if 'chassi' in df_ontem.columns else set()\n",
    "\n",
    "    # Classificar status_beneficio em df\n",
    "    if 'chassi' in df.columns:\n",
    "        df['status_beneficio'] = np.where(df['chassi'].isin(set_ontem), 'ATIVO', 'NOVO')\n",
    "    if 'migration_from' not in df.columns:\n",
    "        df['migration_from'] = 'NULL'\n",
    "\n",
    "    \n",
    "    return df, df_ontem\n",
    "\n",
    "process(df,df_ontem)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9d25af",
   "metadata": {},
   "source": [
    "last function: refining movement NEW boards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "18c2c89f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>placa</th>\n",
       "      <th>chassi</th>\n",
       "      <th>id_placa</th>\n",
       "      <th>id_veiculo</th>\n",
       "      <th>id_carroceria</th>\n",
       "      <th>matricula</th>\n",
       "      <th>conjunto</th>\n",
       "      <th>unidade</th>\n",
       "      <th>consultor</th>\n",
       "      <th>status_beneficio</th>\n",
       "      <th>cliente</th>\n",
       "      <th>data_registro</th>\n",
       "      <th>data_ativacao_beneficio</th>\n",
       "      <th>suporte</th>\n",
       "      <th>data_filtro</th>\n",
       "      <th>empresa</th>\n",
       "      <th>migration_from</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MGC1B11</td>\n",
       "      <td>9BVN4DAA0YE672083</td>\n",
       "      <td>17322444</td>\n",
       "      <td>17322444</td>\n",
       "      <td>0</td>\n",
       "      <td>5175</td>\n",
       "      <td>16639</td>\n",
       "      <td>OPENTRUCK CORRETORA</td>\n",
       "      <td>Gilvana Daros</td>\n",
       "      <td>ATIVO</td>\n",
       "      <td>APROSSIL - ASSOCIACAO DE PROPRIETARIOS DE CAMI...</td>\n",
       "      <td>2025-05-20</td>\n",
       "      <td>2025-06-02</td>\n",
       "      <td>Lucas Belmiro Mendes Santos</td>\n",
       "      <td>2025-08-27</td>\n",
       "      <td>Viavante</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MGA0I88</td>\n",
       "      <td>9BST4X2A043550744</td>\n",
       "      <td>17322241</td>\n",
       "      <td>17322241</td>\n",
       "      <td>0</td>\n",
       "      <td>5175</td>\n",
       "      <td>16639</td>\n",
       "      <td>OPENTRUCK CORRETORA</td>\n",
       "      <td>Gilvana Daros</td>\n",
       "      <td>ATIVO</td>\n",
       "      <td>APROSSIL - ASSOCIACAO DE PROPRIETARIOS DE CAMI...</td>\n",
       "      <td>2025-05-20</td>\n",
       "      <td>2025-06-02</td>\n",
       "      <td>Lucas Belmiro Mendes Santos</td>\n",
       "      <td>2025-08-27</td>\n",
       "      <td>Viavante</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MFJ8H57</td>\n",
       "      <td>9BFVCE1N3ABB42605</td>\n",
       "      <td>17322663</td>\n",
       "      <td>17322663</td>\n",
       "      <td>0</td>\n",
       "      <td>5175</td>\n",
       "      <td>16639</td>\n",
       "      <td>OPENTRUCK CORRETORA</td>\n",
       "      <td>Gilvana Daros</td>\n",
       "      <td>ATIVO</td>\n",
       "      <td>APROSSIL - ASSOCIACAO DE PROPRIETARIOS DE CAMI...</td>\n",
       "      <td>2025-05-20</td>\n",
       "      <td>2025-06-02</td>\n",
       "      <td>Lucas Belmiro Mendes Santos</td>\n",
       "      <td>2025-08-27</td>\n",
       "      <td>Viavante</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MFE4B62</td>\n",
       "      <td>9BSR4X2A053564937</td>\n",
       "      <td>17322315</td>\n",
       "      <td>17322315</td>\n",
       "      <td>0</td>\n",
       "      <td>5175</td>\n",
       "      <td>16639</td>\n",
       "      <td>OPENTRUCK CORRETORA</td>\n",
       "      <td>Gilvana Daros</td>\n",
       "      <td>ATIVO</td>\n",
       "      <td>APROSSIL - ASSOCIACAO DE PROPRIETARIOS DE CAMI...</td>\n",
       "      <td>2025-05-20</td>\n",
       "      <td>2025-06-02</td>\n",
       "      <td>Lucas Belmiro Mendes Santos</td>\n",
       "      <td>2025-08-27</td>\n",
       "      <td>Viavante</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BEX9G24</td>\n",
       "      <td>9ADG0942MMM477102</td>\n",
       "      <td>27469</td>\n",
       "      <td>0</td>\n",
       "      <td>27469</td>\n",
       "      <td>1023</td>\n",
       "      <td>20469</td>\n",
       "      <td>UNIDADE LONDRINA</td>\n",
       "      <td>Daiane Cristina Veiga da Silva</td>\n",
       "      <td>ATIVO</td>\n",
       "      <td>TRANSPORTADORA SEMCHECHEM LTDA</td>\n",
       "      <td>2025-07-14</td>\n",
       "      <td>2025-07-14</td>\n",
       "      <td>Lucas Belmiro Mendes Santos</td>\n",
       "      <td>2025-08-27</td>\n",
       "      <td>Viavante</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32903</th>\n",
       "      <td>QAB1870</td>\n",
       "      <td>94BL0262KKR004389</td>\n",
       "      <td>3485</td>\n",
       "      <td>0</td>\n",
       "      <td>3485</td>\n",
       "      <td>975</td>\n",
       "      <td>1074</td>\n",
       "      <td>UNIDADE CAMPO GRANDE</td>\n",
       "      <td>Icaro Gomes De Oliveira</td>\n",
       "      <td>ATIVO</td>\n",
       "      <td>CEREALISTA ANZIBAS LTDA</td>\n",
       "      <td>2025-08-18</td>\n",
       "      <td>2025-08-19</td>\n",
       "      <td>Diego Alejandro Cortes Moya</td>\n",
       "      <td>2025-08-27</td>\n",
       "      <td>Tag</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32904</th>\n",
       "      <td>MHB9F69</td>\n",
       "      <td>955L14639AS299249</td>\n",
       "      <td>3652</td>\n",
       "      <td>0</td>\n",
       "      <td>3652</td>\n",
       "      <td>993</td>\n",
       "      <td>1116</td>\n",
       "      <td>MICRO A - R A SERVICOS &amp; CONSULTORIA LTDA</td>\n",
       "      <td>Rodrigo Almeida</td>\n",
       "      <td>ATIVO</td>\n",
       "      <td>RAPIDO EXPRESSO EVOLOG TRANSPORTES LTDA</td>\n",
       "      <td>2025-08-18</td>\n",
       "      <td>2025-08-18</td>\n",
       "      <td>Lucas Belmiro Mendes Santos</td>\n",
       "      <td>2025-08-27</td>\n",
       "      <td>Tag</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32905</th>\n",
       "      <td>AXV7H35</td>\n",
       "      <td>9EP081630E1001931</td>\n",
       "      <td>3198</td>\n",
       "      <td>0</td>\n",
       "      <td>3198</td>\n",
       "      <td>1007</td>\n",
       "      <td>1134</td>\n",
       "      <td>MICRO B - T.V PASQUINI SERVICOS ADMINISTRATIVO...</td>\n",
       "      <td>MF - TIAGO PASQUINI</td>\n",
       "      <td>ATIVO</td>\n",
       "      <td>PADROEIRA BR. LOCAÇÕES LTDA</td>\n",
       "      <td>2025-08-18</td>\n",
       "      <td>2025-08-19</td>\n",
       "      <td>Lucas Belmiro Mendes Santos</td>\n",
       "      <td>2025-08-27</td>\n",
       "      <td>Tag</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32906</th>\n",
       "      <td>AJW6D00</td>\n",
       "      <td>955L1463EES359870</td>\n",
       "      <td>3194</td>\n",
       "      <td>0</td>\n",
       "      <td>3194</td>\n",
       "      <td>1007</td>\n",
       "      <td>1134</td>\n",
       "      <td>MICRO B - T.V PASQUINI SERVICOS ADMINISTRATIVO...</td>\n",
       "      <td>MF - TIAGO PASQUINI</td>\n",
       "      <td>ATIVO</td>\n",
       "      <td>PADROEIRA BR. LOCAÇÕES LTDA</td>\n",
       "      <td>2025-08-18</td>\n",
       "      <td>2025-08-19</td>\n",
       "      <td>Lucas Belmiro Mendes Santos</td>\n",
       "      <td>2025-08-27</td>\n",
       "      <td>Tag</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32907</th>\n",
       "      <td>ESU7G77</td>\n",
       "      <td>9BSP4X200C3805546</td>\n",
       "      <td>339080</td>\n",
       "      <td>339080</td>\n",
       "      <td>0</td>\n",
       "      <td>1039</td>\n",
       "      <td>1912</td>\n",
       "      <td>CO.CO - MD REPRESENTACAO COMERCIAL LTDA</td>\n",
       "      <td>CS - MD REPRESENTACAO COMERCIAL LTDA</td>\n",
       "      <td>NOVO</td>\n",
       "      <td>M V DOS SANTOS TRANSPORTES</td>\n",
       "      <td>2025-08-26</td>\n",
       "      <td>2025-08-26</td>\n",
       "      <td>Lucas Lobo Didur</td>\n",
       "      <td>2025-08-27</td>\n",
       "      <td>Tag</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32908 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         placa             chassi  id_placa  id_veiculo  id_carroceria  \\\n",
       "0      MGC1B11  9BVN4DAA0YE672083  17322444    17322444              0   \n",
       "1      MGA0I88  9BST4X2A043550744  17322241    17322241              0   \n",
       "2      MFJ8H57  9BFVCE1N3ABB42605  17322663    17322663              0   \n",
       "3      MFE4B62  9BSR4X2A053564937  17322315    17322315              0   \n",
       "4      BEX9G24  9ADG0942MMM477102     27469           0          27469   \n",
       "...        ...                ...       ...         ...            ...   \n",
       "32903  QAB1870  94BL0262KKR004389      3485           0           3485   \n",
       "32904  MHB9F69  955L14639AS299249      3652           0           3652   \n",
       "32905  AXV7H35  9EP081630E1001931      3198           0           3198   \n",
       "32906  AJW6D00  955L1463EES359870      3194           0           3194   \n",
       "32907  ESU7G77  9BSP4X200C3805546    339080      339080              0   \n",
       "\n",
       "       matricula  conjunto                                            unidade  \\\n",
       "0           5175     16639                                OPENTRUCK CORRETORA   \n",
       "1           5175     16639                                OPENTRUCK CORRETORA   \n",
       "2           5175     16639                                OPENTRUCK CORRETORA   \n",
       "3           5175     16639                                OPENTRUCK CORRETORA   \n",
       "4           1023     20469                                   UNIDADE LONDRINA   \n",
       "...          ...       ...                                                ...   \n",
       "32903        975      1074                               UNIDADE CAMPO GRANDE   \n",
       "32904        993      1116          MICRO A - R A SERVICOS & CONSULTORIA LTDA   \n",
       "32905       1007      1134  MICRO B - T.V PASQUINI SERVICOS ADMINISTRATIVO...   \n",
       "32906       1007      1134  MICRO B - T.V PASQUINI SERVICOS ADMINISTRATIVO...   \n",
       "32907       1039      1912            CO.CO - MD REPRESENTACAO COMERCIAL LTDA   \n",
       "\n",
       "                                  consultor status_beneficio  \\\n",
       "0                             Gilvana Daros            ATIVO   \n",
       "1                             Gilvana Daros            ATIVO   \n",
       "2                             Gilvana Daros            ATIVO   \n",
       "3                             Gilvana Daros            ATIVO   \n",
       "4            Daiane Cristina Veiga da Silva            ATIVO   \n",
       "...                                     ...              ...   \n",
       "32903               Icaro Gomes De Oliveira            ATIVO   \n",
       "32904                       Rodrigo Almeida            ATIVO   \n",
       "32905                   MF - TIAGO PASQUINI            ATIVO   \n",
       "32906                   MF - TIAGO PASQUINI            ATIVO   \n",
       "32907  CS - MD REPRESENTACAO COMERCIAL LTDA             NOVO   \n",
       "\n",
       "                                                 cliente data_registro  \\\n",
       "0      APROSSIL - ASSOCIACAO DE PROPRIETARIOS DE CAMI...    2025-05-20   \n",
       "1      APROSSIL - ASSOCIACAO DE PROPRIETARIOS DE CAMI...    2025-05-20   \n",
       "2      APROSSIL - ASSOCIACAO DE PROPRIETARIOS DE CAMI...    2025-05-20   \n",
       "3      APROSSIL - ASSOCIACAO DE PROPRIETARIOS DE CAMI...    2025-05-20   \n",
       "4                         TRANSPORTADORA SEMCHECHEM LTDA    2025-07-14   \n",
       "...                                                  ...           ...   \n",
       "32903                            CEREALISTA ANZIBAS LTDA    2025-08-18   \n",
       "32904            RAPIDO EXPRESSO EVOLOG TRANSPORTES LTDA    2025-08-18   \n",
       "32905                        PADROEIRA BR. LOCAÇÕES LTDA    2025-08-18   \n",
       "32906                        PADROEIRA BR. LOCAÇÕES LTDA    2025-08-18   \n",
       "32907                         M V DOS SANTOS TRANSPORTES    2025-08-26   \n",
       "\n",
       "      data_ativacao_beneficio                      suporte data_filtro  \\\n",
       "0                  2025-06-02  Lucas Belmiro Mendes Santos  2025-08-27   \n",
       "1                  2025-06-02  Lucas Belmiro Mendes Santos  2025-08-27   \n",
       "2                  2025-06-02  Lucas Belmiro Mendes Santos  2025-08-27   \n",
       "3                  2025-06-02  Lucas Belmiro Mendes Santos  2025-08-27   \n",
       "4                  2025-07-14  Lucas Belmiro Mendes Santos  2025-08-27   \n",
       "...                       ...                          ...         ...   \n",
       "32903              2025-08-19  Diego Alejandro Cortes Moya  2025-08-27   \n",
       "32904              2025-08-18  Lucas Belmiro Mendes Santos  2025-08-27   \n",
       "32905              2025-08-19  Lucas Belmiro Mendes Santos  2025-08-27   \n",
       "32906              2025-08-19  Lucas Belmiro Mendes Santos  2025-08-27   \n",
       "32907              2025-08-26             Lucas Lobo Didur  2025-08-27   \n",
       "\n",
       "        empresa  migration_from  \n",
       "0      Viavante             NaN  \n",
       "1      Viavante             NaN  \n",
       "2      Viavante             NaN  \n",
       "3      Viavante             NaN  \n",
       "4      Viavante             NaN  \n",
       "...         ...             ...  \n",
       "32903       Tag             NaN  \n",
       "32904       Tag             NaN  \n",
       "32905       Tag             NaN  \n",
       "32906       Tag             NaN  \n",
       "32907       Tag             NaN  \n",
       "\n",
       "[32908 rows x 17 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Refinar NOVO usando df_conferencia (historico por chassi+beneficio)\n",
    "def refining_new_boards(df,df_conf):\n",
    "    try:\n",
    "        # Normalização de chaves\n",
    "        for d in (df_conf):\n",
    "            if 'chassi' in d.columns:\n",
    "                d['chassi'] = d['chassi'].astype(str).str.strip().str.upper()\n",
    "            if 'beneficio' in d.columns:\n",
    "                d['beneficio'] = d['beneficio'].astype(str).str.strip().str.upper()\n",
    "            if 'empresa' in d.columns:\n",
    "                d['empresa'] = d['empresa'].astype(str).str.strip()\n",
    "        # Garantir datetime\n",
    "        if 'data_ativacao_beneficio' in df_conf.columns:\n",
    "            df_conf['data_ativacao_beneficio'] = pd.to_datetime(df_conf['data_ativacao_beneficio'], errors='coerce')\n",
    "\n",
    "        # Aplicar apenas nas linhas marcadas como NOVO e que tenham chassi+beneficio\n",
    "        mask_novo = df['status_beneficio'].eq('NOVO')\n",
    "        if mask_novo.any() and {'chassi','beneficio'}.issubset(df.columns) and not df_conf.empty and {'chassi','beneficio','data_ativacao_beneficio','status_beneficio','empresa'}.issubset(df_conf.columns):\n",
    "            df_novos = df.loc[mask_novo, ['chassi','beneficio','empresa']].copy()\n",
    "            df_novos['beneficio'] = df_novos['beneficio'].astype(str).str.strip().str.upper()\n",
    "            df_novos['empresa'] = df_novos['empresa'].astype(str).str.strip()\n",
    "\n",
    "            # Contagem de registros por par\n",
    "            hist_counts = (df_conf\n",
    "                .groupby(['chassi','beneficio'], as_index=False)\n",
    "                .size()\n",
    "                .rename(columns={'size':'hist_count'}))\n",
    "\n",
    "            # Penúltimo registro por par: ordenar desc e pegar a 2a linha (index 1)\n",
    "            df_conf_sorted = df_conf.sort_values('data_ativacao_beneficio', ascending=False)\n",
    "            penult = (df_conf_sorted\n",
    "                .groupby(['chassi','beneficio'], as_index=False)\n",
    "                .nth(1)\n",
    "                .reset_index(drop=False))\n",
    "            # Selecionar colunas relevantes\n",
    "            penult = penult[['chassi','beneficio','status_beneficio','empresa']].rename(columns={\n",
    "                'status_beneficio':'status_penultimo',\n",
    "                'empresa':'empresa_penultima'\n",
    "            })\n",
    "\n",
    "            # Merge info de histórico e penúltimo nas linhas NOVO\n",
    "            df_novos = df_novos.merge(hist_counts, on=['chassi','beneficio'], how='left')\n",
    "            df_novos = df_novos.merge(penult, on=['chassi','beneficio'], how='left')\n",
    "\n",
    "            # Regras:\n",
    "            # - hist_count <= 1 -> permanece NOVO\n",
    "            # - hist_count > 1:\n",
    "            #   - status_penultimo in status_filter_list -> REATIVAÇÃO\n",
    "            #   - else: se empresa_penultima != empresa_atual -> MIGRAÇÃO (migration_from = empresa_penultima)\n",
    "            #           senão -> RENOVAÇÃO\n",
    "            cond_hist_many = (df_novos['hist_count'].fillna(0) > 1)\n",
    "            cond_penult_cancel = df_novos['status_penultimo'].isin(status_filter_list)\n",
    "            cond_mudou_empresa = df_novos['empresa_penultima'].notna() & df_novos['empresa'].notna() & (df_novos['empresa_penultima'] != df_novos['empresa'])\n",
    "\n",
    "            # Inicial\n",
    "            df_novos['novo_status'] = 'NOVO'\n",
    "            df_novos['novo_migration_from'] = 'NULL'\n",
    "\n",
    "            # REATIVAÇÃO\n",
    "            reativ_mask = cond_hist_many & cond_penult_cancel\n",
    "            df_novos.loc[reativ_mask, 'novo_status'] = 'REATIVAÇÃO'\n",
    "            df_novos.loc[reativ_mask, 'novo_migration_from'] = 'NULL'\n",
    "\n",
    "            # MIGRAÇÃO\n",
    "            migr_mask = cond_hist_many & ~cond_penult_cancel & cond_mudou_empresa\n",
    "            df_novos.loc[migr_mask, 'novo_status'] = 'MIGRAÇÃO'\n",
    "            df_novos.loc[migr_mask, 'novo_migration_from'] = df_novos.loc[migr_mask, 'empresa_penultima']\n",
    "\n",
    "            # RENOVAÇÃO\n",
    "            renov_mask = cond_hist_many & ~cond_penult_cancel & ~cond_mudou_empresa\n",
    "            df_novos.loc[renov_mask, 'novo_status'] = 'RENOVAÇÃO'\n",
    "            df_novos.loc[renov_mask, 'novo_migration_from'] = 'NULL'\n",
    "\n",
    "            # Aplicar de volta no df\n",
    "            df.loc[mask_novo, 'status_beneficio'] = df_novos['novo_status'].values\n",
    "            df.loc[mask_novo, 'migration_from'] = df_novos['novo_migration_from'].values\n",
    "    except Exception as e:\n",
    "        logging.info(f\"Falha ao refinar NOVO com histórico: {e}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "refining_new_boards(df,df_conferencia)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e0a8372a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\n",
      "32802\n"
     ]
    }
   ],
   "source": [
    "df_novos = df[df['status_beneficio']=='NOVO']\n",
    "df_ativos = df[df['status_beneficio']=='ATIVO']\n",
    "\n",
    "print(df_novos.shape[0])\n",
    "print(df_ativos.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332b0467",
   "metadata": {},
   "source": [
    "loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "62bcf5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlsx_path = r\"C:\\Users\\raphael.almeida\\Documents\\Processos\\placas_movimentacoes\\df_tratado.xlsx\"\n",
    "df_ativacoes_tratado = df.to_excel(xlsx_path, engine='openpyxl', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8755af",
   "metadata": {},
   "source": [
    "bkp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380a559a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANDO MÓDULOS E PACOTES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "import awswrangler as awr\n",
    "\n",
    "xlsx_ontem = r\"C:\\Users\\raphael.almeida\\Documents\\Processos\\placas_movimentacoes\\placas_movimentacoes_ontem.xlsx\"\n",
    "xlsx = r\"C:\\Users\\raphael.almeida\\Documents\\Processos\\placas_movimentacoes\\placas_movimentacoes.xlsx\"\n",
    "\n",
    "df_ontem = pd.read_excel(xlsx_ontem, engine='openpyxl', sheet_name= 'ATIVAÇÕES')\n",
    "df = pd.read_excel(xlsx, engine='openpyxl')\n",
    "status_filter_list = ['CANCELADO', 'CANCELADA', 'FINALIZADO', 'FINALIZADA', 'NAO RENOVADO']\n",
    "\n",
    "path = r\"C:\\Users\\raphael.almeida\\Documents\\Processos\\placas_movimentacoes\"\n",
    "dir_query = os.path.join(path,'sql', 'listagem_mestra.sql')\n",
    "\n",
    "with open(dir_query, 'r') as file:\n",
    "    query = file.read()\n",
    "\n",
    "df_conferencia = awr.athena.read_sql_query(query, database='silver')\n",
    "\n",
    "class ChassiProcessor:\n",
    "    \n",
    "    def process(df, df_ontem, df_conf):\n",
    "        # Normalizar chassi em ambos os dataframes\n",
    "        for d in (df, df_ontem):\n",
    "            if 'chassi' in d.columns:\n",
    "                d['chassi'] = d['chassi'].astype(str).str.strip().str.upper()\n",
    "\n",
    "        # Conjuntos para comparação\n",
    "        set_hoje = set(df['chassi'].dropna().unique()) if 'chassi' in df.columns else set()\n",
    "        set_ontem = set(df_ontem['chassi'].dropna().unique()) if 'chassi' in df_ontem.columns else set()\n",
    "\n",
    "        # Classificar status_beneficio em df\n",
    "        if 'chassi' in df.columns:\n",
    "            df['status_beneficio'] = np.where(df['chassi'].isin(set_ontem), 'ATIVO', 'NOVO')\n",
    "        if 'migration_from' not in df.columns:\n",
    "            df['migration_from'] = 'NULL'\n",
    "\n",
    "        # Construir df_cancelados: existiam ontem e não existem hoje\n",
    "        if 'chassi' in df_ontem.columns:\n",
    "            cancelados_mask = ~df_ontem['chassi'].isin(set_hoje)\n",
    "            df_cancelados = df_ontem.loc[cancelados_mask].copy()\n",
    "        else:\n",
    "            df_cancelados = pd.DataFrame(columns=df_ontem.columns)\n",
    "\n",
    "        # Refinar NOVO usando df_conferencia (historico por chassi+beneficio)\n",
    "        try:\n",
    "\n",
    "            # Normalização de chaves\n",
    "            for d in (df_conf):\n",
    "                if 'chassi' in d.columns:\n",
    "                    d['chassi'] = d['chassi'].astype(str).str.strip().str.upper()\n",
    "                if 'beneficio' in d.columns:\n",
    "                    d['beneficio'] = d['beneficio'].astype(str).str.strip().str.upper()\n",
    "                if 'empresa' in d.columns:\n",
    "                    d['empresa'] = d['empresa'].astype(str).str.strip()\n",
    "            # Garantir datetime\n",
    "            if 'data_ativacao_beneficio' in df_conf.columns:\n",
    "                df_conf['data_ativacao_beneficio'] = pd.to_datetime(df_conf['data_ativacao_beneficio'], errors='coerce')\n",
    "\n",
    "            # Aplicar apenas nas linhas marcadas como NOVO e que tenham chassi+beneficio\n",
    "            mask_novo = df['status_beneficio'].eq('NOVO')\n",
    "            if mask_novo.any() and {'chassi','beneficio'}.issubset(df.columns) and not df_conf.empty and {'chassi','beneficio','data_ativacao_beneficio','status_beneficio','empresa'}.issubset(df_conf.columns):\n",
    "                df_novos = df.loc[mask_novo, ['chassi','beneficio','empresa']].copy()\n",
    "                df_novos['beneficio'] = df_novos['beneficio'].astype(str).str.strip().str.upper()\n",
    "                df_novos['empresa'] = df_novos['empresa'].astype(str).str.strip()\n",
    "\n",
    "                # Contagem de registros por par\n",
    "                hist_counts = (df_conf\n",
    "                    .groupby(['chassi','beneficio'], as_index=False)\n",
    "                    .size()\n",
    "                    .rename(columns={'size':'hist_count'}))\n",
    "\n",
    "                # Penúltimo registro por par: ordenar desc e pegar a 2a linha (index 1)\n",
    "                df_conf_sorted = df_conf.sort_values('data_ativacao_beneficio', ascending=False)\n",
    "                penult = (df_conf_sorted\n",
    "                    .groupby(['chassi','beneficio'], as_index=False)\n",
    "                    .nth(1)\n",
    "                    .reset_index(drop=False))\n",
    "                # Selecionar colunas relevantes\n",
    "                penult = penult[['chassi','beneficio','status_beneficio','empresa']].rename(columns={\n",
    "                    'status_beneficio':'status_penultimo',\n",
    "                    'empresa':'empresa_penultima'\n",
    "                })\n",
    "\n",
    "                # Merge info de histórico e penúltimo nas linhas NOVO\n",
    "                df_novos = df_novos.merge(hist_counts, on=['chassi','beneficio'], how='left')\n",
    "                df_novos = df_novos.merge(penult, on=['chassi','beneficio'], how='left')\n",
    "\n",
    "                # Regras:\n",
    "                # - hist_count <= 1 -> permanece NOVO\n",
    "                # - hist_count > 1:\n",
    "                #   - status_penultimo in status_filter_list -> REATIVAÇÃO\n",
    "                #   - else: se empresa_penultima != empresa_atual -> MIGRAÇÃO (migration_from = empresa_penultima)\n",
    "                #           senão -> RENOVAÇÃO\n",
    "                cond_hist_many = (df_novos['hist_count'].fillna(0) > 1)\n",
    "                cond_penult_cancel = df_novos['status_penultimo'].isin(status_filter_list)\n",
    "                cond_mudou_empresa = df_novos['empresa_penultima'].notna() & df_novos['empresa'].notna() & (df_novos['empresa_penultima'] != df_novos['empresa'])\n",
    "\n",
    "                # Inicial\n",
    "                df_novos['novo_status'] = 'NOVO'\n",
    "                df_novos['novo_migration_from'] = 'NULL'\n",
    "\n",
    "                # REATIVAÇÃO\n",
    "                reativ_mask = cond_hist_many & cond_penult_cancel\n",
    "                df_novos.loc[reativ_mask, 'novo_status'] = 'REATIVAÇÃO'\n",
    "                df_novos.loc[reativ_mask, 'novo_migration_from'] = 'NULL'\n",
    "\n",
    "                # MIGRAÇÃO\n",
    "                migr_mask = cond_hist_many & ~cond_penult_cancel & cond_mudou_empresa\n",
    "                df_novos.loc[migr_mask, 'novo_status'] = 'MIGRAÇÃO'\n",
    "                df_novos.loc[migr_mask, 'novo_migration_from'] = df_novos.loc[migr_mask, 'empresa_penultima']\n",
    "\n",
    "                # RENOVAÇÃO\n",
    "                renov_mask = cond_hist_many & ~cond_penult_cancel & ~cond_mudou_empresa\n",
    "                df_novos.loc[renov_mask, 'novo_status'] = 'RENOVAÇÃO'\n",
    "                df_novos.loc[renov_mask, 'novo_migration_from'] = 'NULL'\n",
    "\n",
    "                # Aplicar de volta no df\n",
    "                df.loc[mask_novo, 'status_beneficio'] = df_novos['novo_status'].values\n",
    "                df.loc[mask_novo, 'migration_from'] = df_novos['novo_migration_from'].values\n",
    "        except Exception as e:\n",
    "            logging.info(f\"Falha ao refinar NOVO com histórico: {e}\")\n",
    "\n",
    "        return df, df_ontem, df_cancelados\n",
    "\n",
    "\n",
    "ChassiProcessor.process(df, df_ontem, df_conferencia)\n",
    "\n",
    "xlsx_path = r\"C:\\Users\\raphael.almeida\\Documents\\Processos\\placas_movimentacoes\\df_tratado.xlsx\"\n",
    "df_ativacoes_tratado = df.to_excel(xlsx_path, engine='openpyxl', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edf2c632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32908"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_ativacoes_ativos = df_final_ativacoes[df_final_ativacoes['status_beneficio']=='ATIVO']\n",
    "df_final_ativacoes_ativos.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf883657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>placa</th>\n",
       "      <th>chassi</th>\n",
       "      <th>id_placa</th>\n",
       "      <th>id_veiculo</th>\n",
       "      <th>id_carroceria</th>\n",
       "      <th>matricula</th>\n",
       "      <th>conjunto</th>\n",
       "      <th>unidade</th>\n",
       "      <th>consultor</th>\n",
       "      <th>status_beneficio</th>\n",
       "      <th>cliente</th>\n",
       "      <th>data_registro</th>\n",
       "      <th>data_ativacao_beneficio</th>\n",
       "      <th>suporte</th>\n",
       "      <th>data_filtro</th>\n",
       "      <th>empresa</th>\n",
       "      <th>migration_from</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31977</th>\n",
       "      <td>TAX8B12</td>\n",
       "      <td>9539J8TH9SR202365</td>\n",
       "      <td>15566883</td>\n",
       "      <td>15566883</td>\n",
       "      <td>0</td>\n",
       "      <td>5485</td>\n",
       "      <td>8355</td>\n",
       "      <td>UNIDADE LONDRINA</td>\n",
       "      <td>Gismary Orasmo</td>\n",
       "      <td>ATIVO</td>\n",
       "      <td>SANTORINI TRANSPORTE E LOGISTICA LTDA</td>\n",
       "      <td>2025-01-16</td>\n",
       "      <td>2025-01-16</td>\n",
       "      <td>Camilla Minho</td>\n",
       "      <td>2025-08-27</td>\n",
       "      <td>Viavante</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31979</th>\n",
       "      <td>TAX8B23</td>\n",
       "      <td>9539J8TH0SR203680</td>\n",
       "      <td>15566726</td>\n",
       "      <td>15566726</td>\n",
       "      <td>0</td>\n",
       "      <td>5485</td>\n",
       "      <td>8355</td>\n",
       "      <td>UNIDADE LONDRINA</td>\n",
       "      <td>Gismary Orasmo</td>\n",
       "      <td>ATIVO</td>\n",
       "      <td>SANTORINI TRANSPORTE E LOGISTICA LTDA</td>\n",
       "      <td>2025-01-16</td>\n",
       "      <td>2025-01-16</td>\n",
       "      <td>Camilla Minho</td>\n",
       "      <td>2025-08-27</td>\n",
       "      <td>Viavante</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31980</th>\n",
       "      <td>PHT5C27</td>\n",
       "      <td>97TD0N412K2001627</td>\n",
       "      <td>14227</td>\n",
       "      <td>0</td>\n",
       "      <td>14227</td>\n",
       "      <td>5488</td>\n",
       "      <td>8360</td>\n",
       "      <td>UNIDADE CUIABA</td>\n",
       "      <td>Isabella Santos</td>\n",
       "      <td>ATIVO</td>\n",
       "      <td>JAFRE RANGEL DE SOUZA</td>\n",
       "      <td>2025-01-16</td>\n",
       "      <td>2025-01-16</td>\n",
       "      <td>João Paulo Ribeiro Pinto</td>\n",
       "      <td>2025-08-27</td>\n",
       "      <td>Viavante</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31982</th>\n",
       "      <td>OKH0A38</td>\n",
       "      <td>9BVAG30C8EE824746</td>\n",
       "      <td>17376787</td>\n",
       "      <td>17376787</td>\n",
       "      <td>0</td>\n",
       "      <td>5489</td>\n",
       "      <td>18138</td>\n",
       "      <td>UNIDADE VILHENA</td>\n",
       "      <td>Vilma Girioli</td>\n",
       "      <td>ATIVO</td>\n",
       "      <td>CLEUVERSON PAZ REIS</td>\n",
       "      <td>2025-06-10</td>\n",
       "      <td>2025-06-10</td>\n",
       "      <td>Camilla Minho</td>\n",
       "      <td>2025-08-27</td>\n",
       "      <td>Viavante</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31984</th>\n",
       "      <td>RQP8I07</td>\n",
       "      <td>953998TH7NR202118</td>\n",
       "      <td>15928702</td>\n",
       "      <td>15928702</td>\n",
       "      <td>0</td>\n",
       "      <td>5493</td>\n",
       "      <td>8364</td>\n",
       "      <td>UNIDADE VILHENA</td>\n",
       "      <td>Vilma Girioli</td>\n",
       "      <td>ATIVO</td>\n",
       "      <td>JHONATAN MIRANDA PESSOA</td>\n",
       "      <td>2025-01-16</td>\n",
       "      <td>2025-01-16</td>\n",
       "      <td>VICTOR GABRIEL GOMES PICÃO</td>\n",
       "      <td>2025-08-27</td>\n",
       "      <td>Viavante</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         placa             chassi  id_placa  id_veiculo  id_carroceria  \\\n",
       "31977  TAX8B12  9539J8TH9SR202365  15566883    15566883              0   \n",
       "31979  TAX8B23  9539J8TH0SR203680  15566726    15566726              0   \n",
       "31980  PHT5C27  97TD0N412K2001627     14227           0          14227   \n",
       "31982  OKH0A38  9BVAG30C8EE824746  17376787    17376787              0   \n",
       "31984  RQP8I07  953998TH7NR202118  15928702    15928702              0   \n",
       "\n",
       "       matricula  conjunto           unidade        consultor  \\\n",
       "31977       5485      8355  UNIDADE LONDRINA   Gismary Orasmo   \n",
       "31979       5485      8355  UNIDADE LONDRINA   Gismary Orasmo   \n",
       "31980       5488      8360    UNIDADE CUIABA  Isabella Santos   \n",
       "31982       5489     18138   UNIDADE VILHENA    Vilma Girioli   \n",
       "31984       5493      8364   UNIDADE VILHENA    Vilma Girioli   \n",
       "\n",
       "      status_beneficio                                cliente data_registro  \\\n",
       "31977            ATIVO  SANTORINI TRANSPORTE E LOGISTICA LTDA    2025-01-16   \n",
       "31979            ATIVO  SANTORINI TRANSPORTE E LOGISTICA LTDA    2025-01-16   \n",
       "31980            ATIVO                  JAFRE RANGEL DE SOUZA    2025-01-16   \n",
       "31982            ATIVO                    CLEUVERSON PAZ REIS    2025-06-10   \n",
       "31984            ATIVO                JHONATAN MIRANDA PESSOA    2025-01-16   \n",
       "\n",
       "      data_ativacao_beneficio                     suporte data_filtro  \\\n",
       "31977              2025-01-16               Camilla Minho  2025-08-27   \n",
       "31979              2025-01-16               Camilla Minho  2025-08-27   \n",
       "31980              2025-01-16    João Paulo Ribeiro Pinto  2025-08-27   \n",
       "31982              2025-06-10               Camilla Minho  2025-08-27   \n",
       "31984              2025-01-16  VICTOR GABRIEL GOMES PICÃO  2025-08-27   \n",
       "\n",
       "        empresa migration_from  \n",
       "31977  Viavante           NULL  \n",
       "31979  Viavante           NULL  \n",
       "31980  Viavante           NULL  \n",
       "31982  Viavante           NULL  \n",
       "31984  Viavante           NULL  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_ativacoes_ativos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5369841f",
   "metadata": {},
   "source": [
    "transformando as planilhas excel em dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f13b0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlsx_ontem = r\"C:\\Users\\raphael.almeida\\Documents\\Processos\\placas_movimentacoes\\placas_movimentacoes_ontem.xlsx\"\n",
    "xlsx = r\"C:\\Users\\raphael.almeida\\Documents\\Processos\\placas_movimentacoes\\placas_movimentacoes.xlsx\"\n",
    "\n",
    "df_ontem = pd.read_excel(xlsx_ontem, engine='openpyxl', sheet_name= 'ATIVAÇÕES')\n",
    "df = pd.read_excel(xlsx, engine='openpyxl')\n",
    "status_filter_list = ['CANCELADO', 'CANCELADA', 'FINALIZADO', 'FINALIZADA', 'NAO RENOVADO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8de12bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ativacoes_tratado2 = Transform.board_status_treatment2(df, df_ontem, df_conf, status_filter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fdeb2bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlsx_path = r\"C:\\Users\\raphael.almeida\\Documents\\Processos\\placas_movimentacoes\\df_tratado.xlsx\"\n",
    "df_ativacoes_tratado.to_excel(xlsx_path, engine='openpyxl', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f618f41c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ATIVO'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ativacoes_tratado2['status_beneficio'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef4e566",
   "metadata": {},
   "source": [
    "# LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf9005b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-26 09:55:58,998 - INFO - \n",
      " ----------------------------------------------------------------------------------\n",
      "2025-08-26 09:55:59,000 - INFO - \n",
      " Processo de Carregamento de Dados concluido com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANDO MÓDULOS E PACOTES\n",
    "import logging\n",
    "import openpyxl\n",
    "import os\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "\n",
    "file_path = r\"C:\\Users\\raphael.almeida\\Documents\\Processos\\placas_acompanhamento\\template\\placas_movimentacoes.xlsx\"\n",
    "destination_dir = r\"C:\\Users\\raphael.almeida\\OneDrive - Grupo Unus\\analise de dados - Arquivos em excel\\Relatório de Ativações Placas\"\n",
    "destination_path = os.path.join(destination_dir, os.path.basename(file_path))\n",
    "\n",
    "with pd.ExcelWriter(destination_path, engine='openpyxl') as writer:\n",
    "    df_final_ativacoes.to_excel(writer, index=False, sheet_name='ATIVAÇÕES')\n",
    "\n",
    "\n",
    "logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "logging.info('\\n Processo de Carregamento de Dados concluido com sucesso!')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
