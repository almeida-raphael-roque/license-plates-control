{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf422456",
   "metadata": {},
   "source": [
    "# EXTRACT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54790159",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-26 11:23:10,188 - INFO - \n",
      " ----------------------------------------------------------------------------------\n",
      "2025-08-26 11:23:10,188 - INFO - \n",
      " Executando Rotina: Movimentação de Placas\n",
      "2025-08-26 11:23:10,221 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 11:23:12,225 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 11:23:13,710 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 11:23:16,171 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 11:23:18,358 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 11:23:20,347 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 11:23:22,240 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 11:23:25,193 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 11:23:27,104 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 11:23:29,017 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 11:23:32,816 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 11:23:34,901 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 11:23:36,856 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 11:23:39,821 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 11:23:41,710 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 11:23:43,631 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 11:23:46,843 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 11:23:48,888 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 11:23:50,775 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 11:23:53,757 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 11:23:55,658 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 11:23:56,501 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 11:23:58,386 - INFO - Created CTAS table \"silver\".\"temp_table_b38d1cb8d8424b5697877c0cf265eb63\"\n",
      "2025-08-26 11:23:58,395 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 11:24:00,394 - INFO - Skipping checksum validation. Response did not contain one of the following algorithms: ['crc32', 'sha1', 'sha256'].\n",
      "2025-08-26 11:24:00,421 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 11:24:01,959 - INFO - Skipping checksum validation. Response did not contain one of the following algorithms: ['crc32', 'sha1', 'sha256'].\n",
      "2025-08-26 11:24:01,986 - INFO - Skipping checksum validation. Response did not contain one of the following algorithms: ['crc32', 'sha1', 'sha256'].\n",
      "2025-08-26 11:24:01,993 - INFO - Skipping checksum validation. Response did not contain one of the following algorithms: ['crc32', 'sha1', 'sha256'].\n",
      "2025-08-26 11:24:02,075 - INFO - Skipping checksum validation. Response did not contain one of the following algorithms: ['crc32', 'sha1', 'sha256'].\n",
      "2025-08-26 11:24:02,657 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 11:24:05,105 - INFO - \n",
      " ----------------------------------------------------------------------------------\n",
      "2025-08-26 11:24:05,106 - INFO - \n",
      " Consulta de ativações extraída com sucesso!\n",
      "2025-08-26 11:24:05,119 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 11:24:07,055 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 11:24:09,480 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 11:24:10,913 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 11:24:12,971 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 11:24:14,912 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 11:24:16,798 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 11:24:19,960 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 11:24:22,037 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 11:24:23,991 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 11:24:27,196 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 11:24:29,086 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 11:24:31,029 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 11:24:33,953 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 11:24:34,825 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 11:24:35,653 - INFO - Created CTAS table \"silver\".\"temp_table_64f056d115d14990affe5f2ab3038468\"\n",
      "2025-08-26 11:24:35,662 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 11:24:37,705 - INFO - Skipping checksum validation. Response did not contain one of the following algorithms: ['crc32', 'sha1', 'sha256'].\n",
      "2025-08-26 11:24:37,718 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 11:24:39,611 - INFO - Skipping checksum validation. Response did not contain one of the following algorithms: ['crc32', 'sha1', 'sha256'].\n",
      "2025-08-26 11:24:39,717 - INFO - Skipping checksum validation. Response did not contain one of the following algorithms: ['crc32', 'sha1', 'sha256'].\n",
      "2025-08-26 11:24:39,855 - INFO - Skipping checksum validation. Response did not contain one of the following algorithms: ['crc32', 'sha1', 'sha256'].\n",
      "2025-08-26 11:24:40,029 - INFO - Skipping checksum validation. Response did not contain one of the following algorithms: ['crc32', 'sha1', 'sha256'].\n",
      "2025-08-26 11:24:40,523 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 11:24:43,315 - INFO - \n",
      " ----------------------------------------------------------------------------------\n",
      "2025-08-26 11:24:43,318 - INFO - \n",
      " Consulta de cancelamentos extraída com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import awswrangler as awr\n",
    "import logging\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Exibe mensagens a partir de INFO\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[\n",
    "        logging.StreamHandler()  # Garante logs no console\n",
    "    ]\n",
    ")\n",
    "\n",
    "logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "logging.info('\\n Executando Rotina: Movimentação de Placas')\n",
    "\n",
    "class Extract:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.path = r\"C:\\Users\\raphael.almeida\\Documents\\Processos\\placas_movimentacoes\"\n",
    "\n",
    "    def extract_all_ativacoes(self):\n",
    "\n",
    "        try:\n",
    "            dir_query = os.path.join(self.path, 'sql', 'all_boards_ATIVOS.sql')\n",
    "            with open(dir_query, 'r') as file:\n",
    "                query = file.read()\n",
    "            df_ativacoes = awr.athena.read_sql_query(query, database='silver')\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info('\\n Consulta de ativações extraída com sucesso!')\n",
    "            return df_ativacoes\n",
    "        except Exception as e:\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'\\n Falha ao extrair a consulta de ativações: {e}')\n",
    "            return None\n",
    "\n",
    "    def extract_all_cancelamentos(self):\n",
    "\n",
    "        try:\n",
    "            dir_query = os.path.join(self.path, 'sql', 'all_boards_CANCELADOS.sql')\n",
    "            with open(dir_query, 'r') as file:\n",
    "                query = file.read()\n",
    "            df_cancelamentos = awr.athena.read_sql_query(query, database='silver')\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info('\\n Consulta de cancelamentos extraída com sucesso!')\n",
    "            return df_cancelamentos\n",
    "        except Exception as e:\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'\\n Falha ao extrair a consulta de cancelamentos: {e}')\n",
    "            return None\n",
    "\n",
    "extract = Extract()\n",
    "df_ativacoes = extract.extract_all_ativacoes()\n",
    "df_cancelamentos = extract.extract_all_cancelamentos()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839be64a",
   "metadata": {},
   "source": [
    "# TRANSFORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b6069b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-26 09:50:35,562 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:50:37,911 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:50:40,553 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:50:43,188 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:50:45,327 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:50:47,303 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:50:49,180 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:50:51,140 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:50:54,183 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:50:56,094 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:50:58,025 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:51:01,032 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:51:02,947 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:51:03,885 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:51:05,861 - INFO - Created CTAS table \"silver\".\"temp_table_cf414580838c423e97e39bc775ecbf78\"\n",
      "2025-08-26 09:51:05,873 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:51:06,872 - INFO - Skipping checksum validation. Response did not contain one of the following algorithms: ['crc32', 'sha1', 'sha256'].\n",
      "2025-08-26 09:51:06,893 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:51:08,714 - INFO - Skipping checksum validation. Response did not contain one of the following algorithms: ['crc32', 'sha1', 'sha256'].\n",
      "2025-08-26 09:51:08,765 - INFO - Skipping checksum validation. Response did not contain one of the following algorithms: ['crc32', 'sha1', 'sha256'].\n",
      "2025-08-26 09:51:08,790 - INFO - Skipping checksum validation. Response did not contain one of the following algorithms: ['crc32', 'sha1', 'sha256'].\n",
      "2025-08-26 09:51:09,089 - INFO - Skipping checksum validation. Response did not contain one of the following algorithms: ['crc32', 'sha1', 'sha256'].\n",
      "2025-08-26 09:51:10,284 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:51:12,600 - INFO - \n",
      " ----------------------------------------------------------------------------------\n",
      "2025-08-26 09:51:12,601 - INFO - \n",
      " Relatorio cancelamentos  - Dados Extraidos com sucesso!\n",
      "2025-08-26 09:51:12,611 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:51:14,998 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:51:16,473 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:51:18,947 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:51:21,009 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:51:22,960 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:51:24,850 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:51:27,979 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:51:29,910 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:51:31,923 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:51:35,032 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:51:37,112 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:51:39,073 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:51:42,139 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:51:44,156 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:51:47,333 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:51:49,348 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:51:51,400 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:51:54,433 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:51:56,496 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:51:57,475 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:51:59,542 - INFO - Created CTAS table \"silver\".\"temp_table_db47294c9d0842a7969378082652eb67\"\n",
      "2025-08-26 09:51:59,555 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:52:01,622 - INFO - Skipping checksum validation. Response did not contain one of the following algorithms: ['crc32', 'sha1', 'sha256'].\n",
      "2025-08-26 09:52:01,637 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:52:03,424 - INFO - Skipping checksum validation. Response did not contain one of the following algorithms: ['crc32', 'sha1', 'sha256'].\n",
      "2025-08-26 09:52:03,645 - INFO - Skipping checksum validation. Response did not contain one of the following algorithms: ['crc32', 'sha1', 'sha256'].\n",
      "2025-08-26 09:52:03,818 - INFO - Skipping checksum validation. Response did not contain one of the following algorithms: ['crc32', 'sha1', 'sha256'].\n",
      "2025-08-26 09:52:04,054 - INFO - Skipping checksum validation. Response did not contain one of the following algorithms: ['crc32', 'sha1', 'sha256'].\n",
      "2025-08-26 09:52:08,530 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:52:10,159 - INFO - \n",
      " ----------------------------------------------------------------------------------\n",
      "2025-08-26 09:52:10,160 - INFO - \n",
      " Relatorio ativacoes (Vivante)  - Dados Extraidos com sucesso!\n",
      "2025-08-26 09:52:10,432 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:52:12,929 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:52:15,621 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:52:18,109 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:52:19,315 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:52:21,325 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:52:23,392 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:52:26,668 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:52:29,178 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:52:31,289 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:52:34,341 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:52:36,357 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:52:38,486 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:52:41,627 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:52:43,638 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:52:45,812 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:52:48,050 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:52:48,942 - INFO - Created CTAS table \"silver\".\"temp_table_c182a4d337344c93b3091808ab2aba50\"\n",
      "2025-08-26 09:52:48,955 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:52:50,962 - INFO - Skipping checksum validation. Response did not contain one of the following algorithms: ['crc32', 'sha1', 'sha256'].\n",
      "2025-08-26 09:52:50,993 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:52:52,699 - INFO - Skipping checksum validation. Response did not contain one of the following algorithms: ['crc32', 'sha1', 'sha256'].\n",
      "2025-08-26 09:52:52,707 - INFO - Skipping checksum validation. Response did not contain one of the following algorithms: ['crc32', 'sha1', 'sha256'].\n",
      "2025-08-26 09:52:52,720 - INFO - Skipping checksum validation. Response did not contain one of the following algorithms: ['crc32', 'sha1', 'sha256'].\n",
      "2025-08-26 09:52:52,852 - INFO - Skipping checksum validation. Response did not contain one of the following algorithms: ['crc32', 'sha1', 'sha256'].\n",
      "2025-08-26 09:52:56,135 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-26 09:52:58,753 - INFO - \n",
      " ----------------------------------------------------------------------------------\n",
      "2025-08-26 09:52:58,754 - INFO - \n",
      " Relatorio conferência  - Dados Extraidos com sucesso!\n",
      "2025-08-26 09:52:59,327 - INFO - \n",
      " ----------------------------------------------------------------------------------\n",
      "2025-08-26 09:52:59,328 - INFO - (872, 26)\n",
      "C:\\Users\\raphael.almeida\\AppData\\Local\\Temp\\ipykernel_29980\\2422733778.py:41: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'NULL' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[idx, 'migration_from'] = 'NULL'\n",
      "2025-08-26 09:54:36,109 - INFO - \n",
      " ----------------------------------------------------------------------------------\n",
      "2025-08-26 09:54:36,110 - INFO - Total de linhas processadas: 872\n",
      "2025-08-26 09:54:36,182 - INFO - \n",
      " ----------------------------------------------------------------------------------\n",
      "2025-08-26 09:54:36,183 - INFO - Número de registros ativos na carteira tratado com os dados do dia anterior.\n",
      "2025-08-26 09:54:36,184 - INFO - \n",
      " ----------------------------------------------------------------------------------\n",
      "2025-08-26 09:54:36,184 - INFO - Nnehum registro de ativações para tratamento de dados. Dataframe vazio!\n",
      "2025-08-26 09:54:36,185 - INFO - \n",
      " ----------------------------------------------------------------------------------\n",
      "2025-08-26 09:54:36,185 - INFO - (14, 26)\n",
      "C:\\Users\\raphael.almeida\\AppData\\Local\\Temp\\ipykernel_29980\\2422733778.py:41: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'NULL' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[idx, 'migration_from'] = 'NULL'\n",
      "2025-08-26 09:54:37,573 - INFO - \n",
      " ----------------------------------------------------------------------------------\n",
      "2025-08-26 09:54:37,575 - INFO - Total de linhas processadas: 14\n",
      "2025-08-26 09:54:37,576 - INFO - \n",
      " ----------------------------------------------------------------------------------\n",
      "2025-08-26 09:54:37,577 - INFO - Nnehum registro de ativações para tratamento de dados. Dataframe vazio!\n",
      "2025-08-26 09:54:37,577 - INFO - \n",
      " ----------------------------------------------------------------------------------\n",
      "2025-08-26 09:54:37,580 - INFO - (344, 26)\n",
      "C:\\Users\\raphael.almeida\\AppData\\Local\\Temp\\ipykernel_29980\\2422733778.py:38: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Viavante' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[idx, 'migration_from'] = verification_penultima_row['empresa'].values[0]\n",
      "2025-08-26 09:55:11,805 - INFO - \n",
      " ----------------------------------------------------------------------------------\n",
      "2025-08-26 09:55:11,806 - INFO - Total de linhas processadas: 344\n",
      "2025-08-26 09:55:11,861 - INFO - \n",
      " ----------------------------------------------------------------------------------\n",
      "2025-08-26 09:55:11,863 - INFO - Processo de Concatenação de Dataframes realizado com sucesso!\n",
      "2025-08-26 09:55:11,908 - INFO - \n",
      " ----------------------------------------------------------------------------------\n",
      "2025-08-26 09:55:11,909 - INFO - Número de registros ativos tratado e corrigido com sucesso.\n",
      "2025-08-26 09:55:12,049 - INFO - \n",
      " ----------------------------------------------------------------------------------\n",
      "2025-08-26 09:55:12,050 - INFO - Falha ao realizar tratamento de dados: 'renegociacao'\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANDO MÓDULOS E PACOTES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import logging\n",
    "import traceback\n",
    "import numpy as np\n",
    "\n",
    "class Transform:\n",
    "        \n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "\n",
    "    def transforming_files(self):\n",
    "\n",
    "        try:\n",
    "\n",
    "            # INICIALIANDO DATAFRAMES VAZIOS\n",
    "            df_final_ativacoes = pd.DataFrame()\n",
    "            df_final_cancelamentos = pd.DataFrame()\n",
    "\n",
    "\n",
    "            # DEFININDO DATA DE INICIO DA CAMPANHA E CRIANDO DATAFRAME COM TODAS AS DATAS DE CAMPANHA\n",
    "            today = dt.date.today()\n",
    "            yesterday = today - dt.timedelta(days=1)\n",
    "            last_friday = today - dt.timedelta(days=3)\n",
    "            comeco_campanha = dt.date(2025, 5, 1)\n",
    "            lista_dias_faltantes = [dt.date(2025,7,20), dt.date(2025,7,28), dt.date(2025,7,29), \n",
    "            dt.date(2025,7,30), dt.date(2025,7,31)]\n",
    "            date_for_all = pd.date_range(start=comeco_campanha, end=today, freq='D')\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info('Falha ao criar parâmetros de data para filtragem de dataframes.')\n",
    "\n",
    "        # EXTRAINDO DATAFRAMES E SEGMENTANDO-OS POR EMPRESA / PADRONIZANDO BENEFICIOS\n",
    "        try:\n",
    "            extract_inst = Extract()\n",
    "            df_final_cancelamentos = extract_inst.extract_all_cancelamentos()\n",
    "            \n",
    "        \n",
    "            df_ativ_all_boards = extract_inst.extract_all_ativacoes()\n",
    "            df_ativ_all_boards['data_ativacao_beneficio'] = pd.to_datetime(df_ativ_all_boards['data_ativacao_beneficio']).dt.date\n",
    "                        \n",
    "            df_ativ_all_boards['beneficio'] = df_ativ_all_boards['beneficio'].replace('REPARAÇÃO OU REPOSIÇÃO DO VEÍCULO', 'CASCO (VEÍCULO)').replace('REPARAÇÃO OU REPOSIÇÃO DO (SEMI)REBOQUE', 'CASCO (R/SR)').replace('REPARAÇÃO OU REPOSIÇÃO DO COMPLEMENTO', 'CASCO (COMPLEMENTO)')\n",
    "            \n",
    "            df_ativ_viavante = df_ativ_all_boards[df_ativ_all_boards['empresa'] == 'Viavante']\n",
    "            df_ativ_stcoop = df_ativ_all_boards[df_ativ_all_boards['empresa'] == 'Stcoop']\n",
    "            df_ativ_segtruck = df_ativ_all_boards[df_ativ_all_boards['empresa'] == 'Segtruck']\n",
    "            df_ativ_tag = df_ativ_all_boards[df_ativ_all_boards['empresa'] == 'Tag']\n",
    "\n",
    "            df_conf_all_boards = extract_inst.extract_conf_boards()\n",
    "            df_conf_all_boards['beneficio'] = df_conf_all_boards['beneficio'].replace('REPARAÇÃO OU REPOSIÇÃO DO VEÍCULO', 'CASCO (VEÍCULO)').replace('REPARAÇÃO OU REPOSIÇÃO DO (SEMI)REBOQUE', 'CASCO (R/SR)').replace('REPARAÇÃO OU REPOSIÇÃO DO COMPLEMENTO', 'CASCO (COMPLEMENTO)')\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')  \n",
    "            logging.info(f'Falha ao realizar a segmentação dos dataframes: {e}')\n",
    "\n",
    "\n",
    "\n",
    "        # SELECIONANDO APENAS AS ATIVAÇÕES CORRESPONDENTES AOS BENEFICIOS 'CASCO' / 'TERCEIRO' POR UM REGEX PADRÃO\n",
    "        try:\n",
    "\n",
    "            ids_beneficios_segtruck = [2, 3, 4, 7, 24, 25, 26, 29]\n",
    "            ids_beneficios_stcoop = [24, 25, 26, 29]\n",
    "            ids_beneficios_viavante = [40, 41, 42, 45]\n",
    "            ids_beneficios_tag = [2, 3, 4, 7, 24, 25, 26, 29, 34, 35, 36, 37, 38, 39]\n",
    "\n",
    "            df_ativ_viavante = df_ativ_viavante.loc[df_ativ_viavante['id_beneficio'].isin(ids_beneficios_viavante)]\n",
    "            df_ativ_stcoop = df_ativ_stcoop[df_ativ_stcoop['id_beneficio'].isin(ids_beneficios_stcoop)]\n",
    "            df_ativ_segtruck = df_ativ_segtruck.loc[df_ativ_segtruck['id_beneficio'].isin(ids_beneficios_segtruck)]\n",
    "            df_ativ_tag = df_ativ_tag.loc[df_ativ_tag['id_beneficio'].isin(ids_beneficios_tag)]\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')  \n",
    "            logging.info(f'Falha ao padronizar nomenclaturas referente aos beneficios pré-estabelecidos: {e}')\n",
    "\n",
    "\n",
    "        # FILTRANDO OS DADOS PELA DATA DE CANCELAMENTO / DATA DE ATUALIZAÇÃO, E ORDENANDO OS DADOS NO DATAFRAME PELAS COLUNAS DE DATA\n",
    "        try:\n",
    "\n",
    "            # IDENTIFICANDO CANCELAMENTOS POR MIGRAÇÃO\n",
    "            #df_final_cancelamentos_integrais = pd.merge(df_final_cancelamentos, df_cancelamentos_dia_anterior_bitrix, on=['conjunto', 'empresa', 'data_cancelamento'], how='left')\n",
    "            #df_final_cancelamentos.drop(columns=['ID'], inplace=True)\n",
    "            df_final_cancelamentos_integrais = df_final_cancelamentos\n",
    "            # FILTRANDO DADOS DE CANCELAMENTOS INTEGRAIS\n",
    "            #df_final_cancelamentos_integrais['data_cancelamento'] = pd.to_datetime(df_final_cancelamentos_integrais['data_cancelamento']).dt.date\n",
    "            #df_final_cancelamentos_integrais['data_substituicao'] = pd.to_datetime(df_final_cancelamentos_integrais['data_substituicao']).dt.date\n",
    "            #if today.weekday() == 0:\n",
    "            #    df_final_cancelamentos_integrais = df_final_cancelamentos_integrais[\n",
    "            #        (df_final_cancelamentos_integrais['data_cancelamento'].between(last_friday, today)) |\n",
    "            #        (df_final_cancelamentos_integrais['data_substituicao'].between(last_friday, today))]\n",
    "            #else:\n",
    "            #    df_final_cancelamentos_integrais = df_final_cancelamentos_integrais[\n",
    "            #        (df_final_cancelamentos_integrais['data_cancelamento'] == yesterday) |\n",
    "            #        (df_final_cancelamentos_integrais['data_substituicao'] == yesterday)]\n",
    "                \n",
    "            # REORDENANDO AS COLUNAS DA BASE DE CANCELAMENTOS INTEGRAIS\n",
    "            #df_final_cancelamentos_integrais = df_final_cancelamentos_integrais[['placa', 'chassi', 'id_placa', 'id_veiculo', 'id_carroceria', 'conjunto', 'unidade', 'status', 'cliente', 'data_registro', 'data_cancelamento', 'suporte', 'data_extracao', 'empresa', 'data_registro_historico', 'migracao', 'renegociacao', 'data_substituicao']]\n",
    "            #df_final_cancelamentos_integrais = df_final_cancelamentos_integrais.sort_values(by=['data_cancelamento', 'data_substituicao'], ascending=True)\n",
    "\n",
    "            \n",
    "        except Exception as e:\n",
    "\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')  \n",
    "            logging.info(f'Falha ao filtrar dados de cancelamentos referente ao dia anterior: {e}')\n",
    "\n",
    "        # CRIANDO COLUNA DE MIGRAÇÃO (MIGRATION_FROM) E DEFININDO FILTRO DE STATUS PARA TRATAMENTO DE DADOS DA CAMPANHA\n",
    "        try:\n",
    "            if not df_ativ_tag.empty:\n",
    "                df_ativ_tag['migration_from'] = np.nan\n",
    "            if not df_ativ_viavante.empty:\n",
    "                df_ativ_viavante['migration_from'] = np.nan\n",
    "            if not df_ativ_stcoop.empty:\n",
    "                df_ativ_stcoop['migration_from'] = np.nan\n",
    "            if not df_ativ_segtruck.empty:\n",
    "                df_ativ_segtruck['migration_from'] = np.nan\n",
    "            if not df_ativ_all_boards.empty:\n",
    "                df_ativ_all_boards['migration_from'] = np.nan\n",
    "\n",
    "            # CRIANDO LISTA DE VERIFICAÇÃOST DE PLACAS MIGRADAS (STATUS)\n",
    "            status_filter_list = ['CANCELADO', 'CANCELADA', 'FINALIZADO', 'FINALIZADA', 'NAO RENOVADO']\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'Falha na ciração das colunas de migração e definição de filtro de status: {e}')\n",
    "\n",
    "\n",
    "        # GERANDO DATAFRAME FINAL (TAG)\n",
    "        '''\n",
    "            AQUI SÃO FILTRADOS OS DADOS PELA DATA DE ATIVAÇÃO DO BENEFICIO, CASO A DATA SEJA UMA SEGUNDA-FEIRA ELE RETORNA OS DADOS DA SEXTA-FEIRA ANTERIOR ATÉ A SEGUNDA-FEIRA\n",
    "            CASO CONTRÁRIO, ELE RETORNA OS DADOS DO DIA ANTERIOR.\n",
    "        '''\n",
    "        try:\n",
    "            \n",
    "            if not df_ativ_tag.empty:\n",
    "                if today.weekday() == 0:\n",
    "                    df_final_tg = df_ativ_tag[df_ativ_tag['data_ativacao_beneficio'].between(last_friday, today)]\n",
    "                else:\n",
    "                    df_final_tg = df_ativ_tag[df_ativ_tag['data_ativacao_beneficio'] == yesterday]\n",
    "            else:\n",
    "                df_final_tg = pd.DataFrame()\n",
    "                logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "                logging.info(f'Nenhum registro de ativação encontrado na Viavante')\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'Falha ao atualizar placas referente a Viavante: {e}')\n",
    "\n",
    "\n",
    "        # GERANDO DATAFRAME FINAL (VIAVANTE)\n",
    "        '''\n",
    "            AQUI SÃO FILTRADOS OS DADOS PELA DATA DE ATIVAÇÃO DO BENEFICIO, CASO A DATA SEJA UMA SEGUNDA-FEIRA ELE RETORNA OS DADOS DA SEXTA-FEIRA ANTERIOR ATÉ A SEGUNDA-FEIRA\n",
    "            CASO CONTRÁRIO, ELE RETORNA OS DADOS DO DIA ANTERIOR.\n",
    "        '''\n",
    "        try:\n",
    "            \n",
    "            if not df_ativ_viavante.empty:\n",
    "                if today.weekday() == 0:\n",
    "                    df_final_viav = df_ativ_viavante[df_ativ_viavante['data_ativacao_beneficio'].between(last_friday, today)]\n",
    "                else:\n",
    "                    df_final_viav = df_ativ_viavante[df_ativ_viavante['data_ativacao_beneficio'] == yesterday]\n",
    "            else:\n",
    "                df_final_viav = pd.DataFrame()\n",
    "                logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "                logging.info(f'Nenhum registro de ativação encontrado na Viavante')\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'Falha ao atualizar placas referente a Viavante: {e}')\n",
    "\n",
    "\n",
    "        # GERANDO DATAFRAME FINAL (STCOOP)\n",
    "        '''\n",
    "            AQUI SÃO FILTRADOS OS DADOS PELA DATA DE ATIVAÇÃO DO BENEFICIO, CASO A DATA SEJA UMA SEGUNDA-FEIRA ELE RETORNA OS DADOS DA SEXTA-FEIRA ANTERIOR ATÉ A SEGUNDA-FEIRA\n",
    "            CASO CONTRÁRIO, ELE RETORNA OS DADOS DO DIA ANTERIOR.\n",
    "        '''\n",
    "        try:\n",
    "            if not df_ativ_stcoop.empty:\n",
    "                if today.weekday() == 0:\n",
    "                    df_final_st = df_ativ_stcoop[df_ativ_stcoop['data_ativacao_beneficio'].between(last_friday, today)]\n",
    "                else:\n",
    "                    df_final_st = df_ativ_stcoop[df_ativ_stcoop['data_ativacao_beneficio'] == yesterday]\n",
    "            else:\n",
    "                df_final_st = pd.DataFrame()\n",
    "                logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "                logging.info(f'Nenhum registro de ativação encontrado na Stcoop')\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'Falha ao atualizar as ativações referente a Stcoop: {e}')\n",
    "\n",
    "        # GERANDO DATAFRAME FINAL (Segtruck)\n",
    "        '''\n",
    "            AQUI SÃO FILTRADOS OS DADOS PELA DATA DE ATIVAÇÃO DO BENEFICIO, CASO A DATA SEJA UMA SEGUNDA-FEIRA ELE RETORNA OS DADOS DA SEXTA-FEIRA ANTERIOR ATÉ A SEGUNDA-FEIRA\n",
    "            CASO CONTRÁRIO, ELE RETORNA OS DADOS DO DIA ANTERIOR.\n",
    "        '''\n",
    "        try:\n",
    "            if not df_ativ_segtruck.empty:\n",
    "                if today.weekday() == 0:\n",
    "                    df_final_seg = df_ativ_segtruck[df_ativ_segtruck['data_ativacao_beneficio'].between(last_friday, today)]\n",
    "                else:\n",
    "                    df_final_seg = df_ativ_segtruck[df_ativ_segtruck['data_ativacao_beneficio'] == yesterday]\n",
    "            else:\n",
    "                df_final_seg = pd.DataFrame()\n",
    "                logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "                logging.info(f'Nenhum registro de ativação encontrado na Segtruck')\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'Falha ao atualizar as ativações referente a Segtruck: {e}')\n",
    "\n",
    "\n",
    "        try:\n",
    "            # PEGANDO DADOS DE ATIVAÇÃO DO DIA ANTERIOR\n",
    "            if not df_ativ_all_boards.empty:\n",
    "                df_ativos_menos_ontem = df_ativ_all_boards[~(df_ativ_all_boards['data_ativacao_beneficio'] == yesterday)]\n",
    "                df_ativos_dia_anterior = df_ativ_all_boards[df_ativ_all_boards['data_ativacao_beneficio'] == yesterday]\n",
    "                df_ativacoes_dia_anterior_ranking_tratado = Transform.board_status_treatment(df=df_ativos_dia_anterior, df_conf=df_conf_all_boards, status_filter_list=status_filter_list)\n",
    "                df_ativacoes_atualizado = pd.concat([df_ativos_menos_ontem, df_ativacoes_dia_anterior_ranking_tratado])\n",
    "                \n",
    "                logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "                logging.info(f'Número de registros ativos na carteira tratado com os dados do dia anterior.')\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'Falha ao incluir registros ativos referente ao dia anterior na contagem . Revise o código: {e}')\n",
    "\n",
    "\n",
    "        # CRIANDO DATAFRAMES FINAIS: ATIVAÇÕES E CANCELAMENTOS\n",
    "        try:\n",
    "            # APLICANDO FUNÇÃO DE TRATAMENTO DE STATUS DAS PLACAS ATIVADAS\n",
    "            df_final_viavante = Transform.board_status_treatment(df=df_final_viav, df_conf=df_conf_all_boards, status_filter_list=status_filter_list)\n",
    "            df_final_stcoop = Transform.board_status_treatment(df=df_final_st, df_conf=df_conf_all_boards, status_filter_list=status_filter_list)\n",
    "            df_final_segtruck = Transform.board_status_treatment(df=df_final_seg, df_conf=df_conf_all_boards, status_filter_list=status_filter_list)\n",
    "            df_final_tag = Transform.board_status_treatment(df=df_final_tg, df_conf=df_conf_all_boards, status_filter_list=status_filter_list)\n",
    "\n",
    "            # CONCATENANDO DATAFRAMES DE ATIVAÇÕES DA CAMPANHA\n",
    "            df_ativacoes_dia_anterior_ranking = pd.concat([df_final_viavante, df_final_stcoop, df_final_segtruck, df_final_tag])\n",
    "            df_ativacoes_dia_anterior_ranking = df_ativacoes_dia_anterior_ranking.sort_values(by='data_ativacao_beneficio', ascending=True)\n",
    "            \n",
    "\n",
    "            # DEFININDO COLUNAS QUE SERÃO UTILIZADAS NOS DATAFRAMES FINAIS\n",
    "\n",
    "            df_final_ativacoes = df_ativacoes_atualizado[[\n",
    "                'placa', 'chassi', 'id_placa', 'id_veiculo', 'id_carroceria', 'matricula', 'conjunto', 'unidade', 'consultor', 'status_beneficio', \n",
    "                'cliente', 'data_registro', 'data_ativacao_beneficio', 'suporte', 'data_filtro', 'empresa', 'migration_from'\n",
    "            ]]\n",
    "\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'Processo de Concatenação de Dataframes realizado com sucesso!')\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'Falha ao unir os dataframes: {e}')\n",
    "\n",
    "        # TRATANDO NÚMERO DE REGISTROS ATIVOS / RETIRANDO DUPLICATAS\n",
    "        try:\n",
    "            df_final_ativacoes = df_final_ativacoes.drop_duplicates(subset='chassi')\n",
    "\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'Número de registros ativos tratado e corrigido com sucesso.')\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'Falha ao tratar e corrigir número de registros ativos. Revise o código: {e}')\n",
    "\n",
    "        # TRATANDO DADOS NULOS NOS DATAFRAMES\n",
    "        try:\n",
    "            df_final_ativacoes['placa'] = df_final_ativacoes['placa'].fillna('SEM-PLACA')\n",
    "            df_final_ativacoes['chassi'] = df_final_ativacoes['chassi'].fillna('NULL')\n",
    "            df_final_ativacoes['id_placa'] = df_final_ativacoes['id_placa'].fillna(0)\n",
    "            df_final_ativacoes['id_veiculo'] = df_final_ativacoes['id_veiculo'].fillna(0)\n",
    "            df_final_ativacoes['id_carroceria'] = df_final_ativacoes['id_carroceria'].fillna(0)\n",
    "            df_final_ativacoes['matricula'] = df_final_ativacoes['matricula'].fillna(0)\n",
    "            df_final_ativacoes['conjunto'] = df_final_ativacoes['conjunto'].fillna(0)\n",
    "            df_final_ativacoes['unidade'] = df_final_ativacoes['unidade'].fillna('NULL')\n",
    "            df_final_ativacoes['consultor'] = df_final_ativacoes['consultor'].fillna('NULL')\n",
    "            df_final_ativacoes['status_beneficio'] = df_final_ativacoes['status_beneficio'].fillna('NULL')\n",
    "            df_final_ativacoes['cliente'] = df_final_ativacoes['cliente'].fillna('NULL')\n",
    "            df_final_ativacoes['data_registro'] = df_final_ativacoes['data_registro'].fillna(pd.Timestamp('1900-01-01'))\n",
    "            df_final_ativacoes['data_ativacao_beneficio'] = df_final_ativacoes['data_ativacao_beneficio'].fillna(pd.Timestamp('1900-01-01'))\n",
    "            df_final_ativacoes['suporte'] = df_final_ativacoes['suporte'].fillna('NULL')\n",
    "            df_final_ativacoes['data_filtro'] = df_final_ativacoes['data_filtro'].fillna(pd.Timestamp('1900-01-01'))\n",
    "            df_final_ativacoes['empresa'] = df_final_ativacoes['empresa'].fillna('NULL')\n",
    "            df_final_ativacoes['migration_from'] = df_final_ativacoes['migration_from'].fillna('NULL')\n",
    "\n",
    "            df_final_cancelamentos_integrais['placa'] = df_final_cancelamentos_integrais['placa'].fillna('SEM-PLACA')\n",
    "            df_final_cancelamentos_integrais['chassi'] = df_final_cancelamentos_integrais['chassi'].fillna('NULL')\n",
    "            df_final_cancelamentos_integrais['id_placa'] = df_final_cancelamentos_integrais['id_placa'].fillna(0)\n",
    "            df_final_cancelamentos_integrais['id_veiculo'] = df_final_cancelamentos_integrais['id_veiculo'].fillna(0)\n",
    "            df_final_cancelamentos_integrais['id_carroceria'] = df_final_cancelamentos_integrais['id_carroceria'].fillna(0)\n",
    "            df_final_cancelamentos_integrais['matricula'] = df_final_cancelamentos_integrais['matricula'].fillna(0)\n",
    "            df_final_cancelamentos_integrais['conjunto'] = df_final_cancelamentos_integrais['conjunto'].fillna(0)\n",
    "            df_final_cancelamentos_integrais['unidade'] = df_final_cancelamentos_integrais['unidade'].fillna('NULL')\n",
    "            df_final_cancelamentos_integrais['status'] = df_final_cancelamentos_integrais['status'].fillna('NULL')\n",
    "            df_final_cancelamentos_integrais['cliente'] = df_final_cancelamentos_integrais['cliente'].fillna('NULL')\n",
    "            df_final_cancelamentos_integrais['data'] = df_final_cancelamentos_integrais['data'].fillna(pd.Timestamp('1900-01-01'))\n",
    "            df_final_cancelamentos_integrais['data_cancelamento'] = df_final_cancelamentos_integrais['data_cancelamento'].fillna(pd.Timestamp('1900-01-01'))\n",
    "            df_final_cancelamentos_integrais['usuario_cancelamento'] = df_final_cancelamentos_integrais['usuario_cancelamento'].fillna('NULL')\n",
    "            df_final_cancelamentos_integrais['data_filtro'] = df_final_cancelamentos_integrais['data_filtro'].fillna(pd.Timestamp('1900-01-01'))\n",
    "            df_final_cancelamentos_integrais['empresa'] = df_final_cancelamentos_integrais['empresa'].fillna('NULL')\n",
    "            df_final_cancelamentos_integrais['migracao'] = df_final_cancelamentos_integrais['migracao'].fillna('NULL')\n",
    "            df_final_cancelamentos_integrais['renegociacao'] = df_final_cancelamentos_integrais['renegociacao'].fillna('NULL')\n",
    "            df_final_cancelamentos_integrais['data_substituicao'] = df_final_cancelamentos_integrais['data_substituicao'].fillna(pd.Timestamp('1900-01-01'))\n",
    "\n",
    "            df_ativacoes_dia_anterior_ranking['placa'] = df_ativacoes_dia_anterior_ranking['placa'].fillna('SEM-PLACA')\n",
    "            df_ativacoes_dia_anterior_ranking['chassi'] = df_ativacoes_dia_anterior_ranking['chassi'].fillna('NULL')\n",
    "            df_ativacoes_dia_anterior_ranking['id_placa'] = df_ativacoes_dia_anterior_ranking['id_placa'].fillna(0)\n",
    "            df_ativacoes_dia_anterior_ranking['id_veiculo'] = df_ativacoes_dia_anterior_ranking['id_veiculo'].fillna(0)\n",
    "            df_ativacoes_dia_anterior_ranking['id_carroceria'] = df_ativacoes_dia_anterior_ranking['id_carroceria'].fillna(0)\n",
    "            df_ativacoes_dia_anterior_ranking['matricula'] = df_ativacoes_dia_anterior_ranking['matricula'].fillna(0)\n",
    "            df_ativacoes_dia_anterior_ranking['conjunto'] = df_ativacoes_dia_anterior_ranking['conjunto'].fillna(0)\n",
    "            df_ativacoes_dia_anterior_ranking['unidade'] = df_ativacoes_dia_anterior_ranking['unidade'].fillna('NULL')\n",
    "            df_ativacoes_dia_anterior_ranking['consultor'] = df_ativacoes_dia_anterior_ranking['consultor'].fillna('NULL')\n",
    "            df_ativacoes_dia_anterior_ranking['status'] = df_ativacoes_dia_anterior_ranking['status'].fillna('NULL')\n",
    "            df_ativacoes_dia_anterior_ranking['cliente'] = df_ativacoes_dia_anterior_ranking['cliente'].fillna('NULL')\n",
    "            df_ativacoes_dia_anterior_ranking['data'] = df_ativacoes_dia_anterior_ranking['data'].fillna(pd.Timestamp('1900-01-01'))\n",
    "            df_ativacoes_dia_anterior_ranking['data_ativacao'] = df_ativacoes_dia_anterior_ranking['data_ativacao'].fillna(pd.Timestamp('1900-01-01'))\n",
    "            df_ativacoes_dia_anterior_ranking['suporte'] = df_ativacoes_dia_anterior_ranking['suporte'].fillna('NULL')\n",
    "            df_ativacoes_dia_anterior_ranking['data_filtro'] = df_ativacoes_dia_anterior_ranking['data_filtro'].fillna(pd.Timestamp('1900-01-01'))\n",
    "            df_ativacoes_dia_anterior_ranking['empresa'] = df_ativacoes_dia_anterior_ranking['empresa'].fillna('NULL')\n",
    "            df_ativacoes_dia_anterior_ranking['migration_from'] = df_ativacoes_dia_anterior_ranking['migration_from'].fillna('NULL')\n",
    "            df_ativacoes_dia_anterior_ranking['coverage'] = df_ativacoes_dia_anterior_ranking['coverage'].fillna(0)\n",
    "            df_ativacoes_dia_anterior_ranking['beneficio'] = df_ativacoes_dia_anterior_ranking['beneficio'].fillna('NULL')\n",
    "            df_ativacoes_dia_anterior_ranking['categoria'] = df_ativacoes_dia_anterior_ranking['categoria'].fillna('NULL')\n",
    "            df_ativacoes_dia_anterior_ranking['tipo_categoria'] = df_ativacoes_dia_anterior_ranking['tipo_categoria'].fillna('NULL')\n",
    "            df_ativacoes_dia_anterior_ranking['data_ativacao_beneficio'] = df_ativacoes_dia_anterior_ranking['data_ativacao_beneficio'].fillna(pd.Timestamp('1900-01-01'))\n",
    "            df_ativacoes_dia_anterior_ranking['status_beneficio'] = df_ativacoes_dia_anterior_ranking['status_beneficio'].fillna('NULL')\n",
    "            df_ativacoes_dia_anterior_ranking['data_atualizacao'] = df_ativacoes_dia_anterior_ranking['data_atualizacao'].fillna(pd.Timestamp('1900-01-01'))\n",
    "            df_ativacoes_dia_anterior_ranking['microfranquia'] = df_ativacoes_dia_anterior_ranking['microfranquia'].fillna('NULL')\n",
    "            df_ativacoes_dia_anterior_ranking['id_beneficio'] = df_ativacoes_dia_anterior_ranking['id_beneficio'].fillna(0)\n",
    "        \n",
    "\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info('\\n Processo de Transformacao de Dados concluido com sucesso!')\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'Falha ao realizar tratamento de dados: {e}')\n",
    "     \n",
    "\n",
    "        return df_final_ativacoes, df_final_cancelamentos_integrais, df_ativacoes_dia_anterior_ranking\n",
    "    \n",
    "transform = Transform()\n",
    "\n",
    "df_final_ativacoes, df_final_cancelamentos_integrais, df_ativacoes_dia_anterior_ranking = transform.transforming_files()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edf2c632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33088"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_ativacoes_ativos = df_final_ativacoes[df_final_ativacoes['status_beneficio']=='ATIVO']\n",
    "df_final_ativacoes_ativos.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef4e566",
   "metadata": {},
   "source": [
    "# LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf9005b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-26 09:55:58,998 - INFO - \n",
      " ----------------------------------------------------------------------------------\n",
      "2025-08-26 09:55:59,000 - INFO - \n",
      " Processo de Carregamento de Dados concluido com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANDO MÓDULOS E PACOTES\n",
    "import logging\n",
    "import openpyxl\n",
    "import shutil\n",
    "import os\n",
    "import traceback\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "\n",
    "\n",
    "file_path = r\"C:\\Users\\raphael.almeida\\Documents\\Processos\\placas_acompanhamento\\template\\placas_movimentacoes.xlsx\"\n",
    "destination_dir = r\"C:\\Users\\raphael.almeida\\OneDrive - Grupo Unus\\analise de dados - Arquivos em excel\\Relatório de Ativações Placas\"\n",
    "destination_path = os.path.join(destination_dir, os.path.basename(file_path))\n",
    "\n",
    "with pd.ExcelWriter(destination_path, engine='openpyxl') as writer:\n",
    "    df_final_ativacoes.to_excel(writer, index=False, sheet_name='ATIVAÇÕES')\n",
    "    df_final_cancelamentos_integrais.to_excel(writer, index=False, sheet_name='CANCELAMENTOS')\n",
    "\n",
    "\n",
    "\n",
    "logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "logging.info('\\n Processo de Carregamento de Dados concluido com sucesso!')\n",
    "\n",
    "\n",
    "\n",
    "    # extract_instance = Extract() #Fazer isso quando a class contiver instâncias \n",
    "\n",
    "    # df_ativacoes = extract_instance.extract_all_ativacoes() #salvando em variáveis os métodos da instância de classe\n",
    "    # df_cancelamentos = extract_instance.extract_all_cancelamentos() \n",
    "    # df_conferencia = extract_instance.extract_conf_boards()\n",
    "   \n",
    "    # Criando uma instância da classe Transform, pois não é uma classe estática (usa self)\n",
    "    # transform_instance = Transform()  # Passando um dicionário vazio como config\n",
    "\n",
    "    # Chamando o método transforming_files da classe Transform, que retorna os DataFrames processados    \n",
    "    # df_final_ativacoes, df_cancelamentos = transform_instance.transforming_files(df_ativacoes, df_cancelamentos, df_conferencia)\n",
    "\n",
    "    # Criando uma instância da classe Load_camp_rank_ativ, pois ela não é estática (usa self)\n",
    "    # load_instance = Load_camp_rank_ativ()\n",
    "\n",
    "    # Chamando o método load_files da instância da classe Load_camp_rank_ativ, passando os DataFrames processados\n",
    "    # load_instance.load_files(df_final_ativacoes, df_cancelamentos)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
