{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf422456",
   "metadata": {},
   "source": [
    "# EXTRACT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54790159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import awswrangler as awr\n",
    "import logging\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Exibe mensagens a partir de INFO\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[\n",
    "        logging.StreamHandler()  # Garante logs no console\n",
    "    ]\n",
    ")\n",
    "\n",
    "logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "logging.info('\\n Executando Rotina: Movimentação de Placas')\n",
    "\n",
    "class Extract:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.path = r\"C:\\Users\\raphael.almeida\\Documents\\Processos\\placas_movimentacoes\"\n",
    "\n",
    "    def extract_all_ativacoes(self):\n",
    "\n",
    "        try:\n",
    "            dir_query = os.path.join(self.path, 'sql', 'all_boards_ATIVOS.sql')\n",
    "            with open(dir_query, 'r') as file:\n",
    "                query = file.read()\n",
    "            df_ativacoes = awr.athena.read_sql_query(query, database='silver')\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info('\\n Consulta de ativações extraída com sucesso!')\n",
    "            return df_ativacoes\n",
    "        except Exception as e:\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'\\n Falha ao extrair a consulta de ativações: {e}')\n",
    "            return None\n",
    "\n",
    "    def extract_all_cancelamentos(self):\n",
    "\n",
    "        try:\n",
    "            dir_query = os.path.join(self.path, 'sql', 'all_boards_CANCELADOS.sql')\n",
    "            with open(dir_query, 'r') as file:\n",
    "                query = file.read()\n",
    "            df_cancelamentos = awr.athena.read_sql_query(query, database='silver')\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info('\\n Consulta de cancelamentos extraída com sucesso!')\n",
    "            return df_cancelamentos\n",
    "        except Exception as e:\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'\\n Falha ao extrair a consulta de cancelamentos: {e}')\n",
    "            return None\n",
    "\n",
    "    def extract_conf_boards(self):\n",
    "\n",
    "        try:\n",
    "\n",
    "            dir_query = os.path.join(self.path,'sql', 'listagem_mestra.sql')\n",
    "\n",
    "            with open(dir_query, 'r') as file:\n",
    "                query = file.read()\n",
    "\n",
    "            df_conferencia = awr.athena.read_sql_query(query, database='silver')\n",
    "        \n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info('\\n Consulta de dados históricos realizada com sucesso!')\n",
    "\n",
    "            return df_conferencia\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'\\n Falha ao extrair consulta de dados históricos: {e}')\n",
    "\n",
    "extract = Extract()\n",
    "df_ativacoes = extract.extract_all_ativacoes()\n",
    "df_cancelamentos = extract.extract_all_cancelamentos()\n",
    "df_conf = extract.extract_conf_boards()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839be64a",
   "metadata": {},
   "source": [
    "# TRANSFORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f270cd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANDO MÓDULOS E PACOTES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "class Transform:\n",
    "        \n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    # CRIANDO FUNÇÃO QUE IRÁ APLICAR O TRATAMENTO DE STATUS DAS PLACAS ATIVADAS\n",
    "    def board_status_treatment(df, df_ontem, df_conf, status_filter_list):\n",
    "\n",
    "        try:\n",
    "            status_filter_list = ['CANCELADO', 'CANCELADA', 'FINALIZADO', 'FINALIZADA', 'NAO RENOVADO']\n",
    "\n",
    "            if not df.empty:\n",
    "                logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "                logging.info(df.shape)\n",
    "                row_count = 0\n",
    "                for idx, row in df.iterrows():\n",
    "                    row_count += 1\n",
    "                    df_comp_ontem = df_ontem[df_ontem['chassi'] == row['chassi']]\n",
    "                    df_comp_conf = df_conf[(df_conf['chassi'] == row['chassi']) & (df_conf['beneficio'] == row['beneficio'])].sort_values(by='data_ativacao', ascending=False)\n",
    "\n",
    "                    if not df_comp_ontem.empty:                                        \n",
    "                                if df_comp_ontem['empresa']!=row['empresa']:\n",
    "                                    df.at[idx, 'status_beneficio'] = 'MIGRAÇÃO'\n",
    "                                    df.at[idx, 'migration_from'] = 'NULL'\n",
    "                                else:\n",
    "                                    df.at[idx, 'status_beneficio'] = 'ATIVO'\n",
    "                                    df.at[idx, 'migration_from'] = 'NULL'                     \n",
    "                    else:\n",
    "                        hist_datas_ativacao = sorted(df_comp_conf['data_ativacao_beneficio'].dropna().drop_duplicates().unique())                    \n",
    "                        if len(hist_datas_ativacao) > 1:\n",
    "                            penultimo_registro_data = hist_datas_ativacao[-2]\n",
    "                            verification_penultima_row = df_comp_conf.loc[df_comp_conf['data_ativacao_beneficio'] == penultimo_registro_data]\n",
    "                            \n",
    "                            if verification_penultima_row['status_beneficio'].values[0] not in status_filter_list:\n",
    "                                if verification_penultima_row['empresa'].values[0] != row['empresa']:\n",
    "                                    df.at[idx, 'status_beneficio'] = 'MIGRAÇÃO' #EM ALGUM MOMENTO ELA ESTAVA COMO ATIVA NA OUTRA EMPRESA, NÃO FOI CANCELADA, MAS TAMBÉM NÃO ESTAVA ATIVA\n",
    "                                    df.at[idx, 'migration_from'] = verification_penultima_row['empresa'].values[0]\n",
    "                                else:\n",
    "                                    df.at[idx, 'status_beneficio'] = 'RENOVAÇÃO' #NÃO TINHA STATUS DE CANCELAMENTO NA EMPRESA, MAS TAMBÉM NÃO ESTAVA ATIVA\n",
    "                                    df.at[idx, 'migration_from'] = 'NULL'\n",
    "                            else:\n",
    "                                    df.at[idx, 'status_beneficio'] = 'REATIVAÇÃO'\n",
    "                                    df.at[idx, 'migration_from'] = 'NULL'\n",
    "                                    \n",
    "                        else:\n",
    "                            df.at[idx, 'status_beneficio'] = 'NOVO'\n",
    "                            df.at[idx, 'migration_from'] = 'NULL'\n",
    "\n",
    "                logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "                logging.info(f'Total de linhas processadas: {row_count}')\n",
    "\n",
    "            else:\n",
    "                logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "                logging.info('Nenhum registro de ativações para tratamento de dados. Dataframe vazio!')\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'Falha no tratamento de status das placas ativadas. Revise o código: {e}')\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93b6069b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANDO MÓDULOS E PACOTES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import logging\n",
    "\n",
    "\n",
    "class Transform:\n",
    "        \n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def transforming_files(self):\n",
    "\n",
    "#DEFININDO DATAFRAMES VAZIOS \n",
    "        try:\n",
    "\n",
    "            df_final_ativacoes = pd.DataFrame()\n",
    "            df_final_cancelamentos = pd.DataFrame()\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info('Falha ao definir dataframes.')\n",
    "\n",
    "#TRANSFORMANDO DF_ATIV E SEGMENTANDO POR EMPRESA\n",
    "        try:\n",
    "            df_ativ_all_boards=df_ativacoes\n",
    "            df_final_cancelamentos=df_cancelamentos\n",
    "            \n",
    "            #extract = Extract()\n",
    "            #df_final_cancelamentos = extract.extract_all_cancelamentos()\n",
    "            #df_ativ_all_boards = extract.extract_all_ativacoes()\n",
    "\n",
    "            df_ativ_all_boards['data_ativacao_beneficio'] = pd.to_datetime(df_ativ_all_boards['data_ativacao_beneficio']).dt.date\n",
    "                        \n",
    "            df_ativ_all_boards['beneficio'] = df_ativ_all_boards['beneficio'].replace('REPARAÇÃO OU REPOSIÇÃO DO VEÍCULO', 'CASCO (VEÍCULO)').replace('REPARAÇÃO OU REPOSIÇÃO DO (SEMI)REBOQUE', 'CASCO (R/SR)').replace('REPARAÇÃO OU REPOSIÇÃO DO COMPLEMENTO', 'CASCO (COMPLEMENTO)')\n",
    "            \n",
    "            df_ativ_viavante = df_ativ_all_boards[df_ativ_all_boards['empresa'] == 'Viavante']\n",
    "            df_ativ_stcoop = df_ativ_all_boards[df_ativ_all_boards['empresa'] == 'Stcoop']\n",
    "            df_ativ_segtruck = df_ativ_all_boards[df_ativ_all_boards['empresa'] == 'Segtruck']\n",
    "            df_ativ_tag = df_ativ_all_boards[df_ativ_all_boards['empresa'] == 'Tag']\n",
    "\n",
    "            df_final_cancelamentos = df_final_cancelamentos\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')  \n",
    "            logging.info(f'Falha ao realizar a segmentação dos dataframes: {e}')\n",
    "\n",
    "# SELECIONANDO APENAS AS ATIVAÇÕES CORRESPONDENTES AOS BENEFICIOS 'CASCO' / 'TERCEIRO' POR UM REGEX PADRÃO\n",
    "        try:\n",
    "            ids_beneficios_segtruck = [2, 3, 4, 7, 24, 25, 26, 29]\n",
    "            ids_beneficios_stcoop = [24, 25, 26, 29]\n",
    "            ids_beneficios_viavante = [40, 41, 42, 45]\n",
    "            ids_beneficios_tag = [2, 3, 4, 7, 24, 25, 26, 29, 34, 35, 36, 37, 38, 39]\n",
    "\n",
    "            df_ativ_viavante = df_ativ_viavante.loc[df_ativ_viavante['id_beneficio'].isin(ids_beneficios_viavante)]\n",
    "            df_ativ_stcoop = df_ativ_stcoop.loc[df_ativ_stcoop['id_beneficio'].isin(ids_beneficios_stcoop)]\n",
    "            df_ativ_segtruck = df_ativ_segtruck.loc[df_ativ_segtruck['id_beneficio'].isin(ids_beneficios_segtruck)]\n",
    "            df_ativ_tag = df_ativ_tag.loc[df_ativ_tag['id_beneficio'].isin(ids_beneficios_tag)]\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')  \n",
    "            logging.info(f'Falha ao padronizar nomenclaturas referente aos beneficios pré-estabelecidos: {e}')\n",
    "\n",
    "# CONCATENANDO E CRIANDO COLUNA DE MIGRAÇÃO (MIGRATION_FROM) \n",
    "        try:\n",
    "\n",
    "            df_final_ativacoes = pd.concat([df_ativ_viavante, df_ativ_stcoop, df_ativ_segtruck, df_ativ_tag])\n",
    "\n",
    "            if not df_final_ativacoes.empty:\n",
    "                df_final_ativacoes['migration_from'] = np.nan\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'Falha na criação da coluna de migração e concatenação de dataframes: {e}')\n",
    "\n",
    "    # DEFININDO COLUNAS QUE SERÃO UTILIZADAS NO DATAFRAME FINAL\n",
    "        try:\n",
    "           \n",
    "            df_final_ativacoes = df_final_ativacoes[[\n",
    "                'placa', 'chassi', 'id_placa', 'id_veiculo', 'id_carroceria', 'matricula', 'conjunto', 'unidade', 'consultor', 'status_beneficio', \n",
    "                'cliente', 'data_registro', 'data_ativacao_beneficio', 'suporte', 'data_filtro', 'empresa', 'migration_from'\n",
    "            ]]\n",
    "\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'Processo de seleção de colunas realizado com sucesso!')\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'Falha ao definir colunas: {e}')\n",
    "\n",
    "    # RETIRANDO DUPLICATAS\n",
    "        try:\n",
    "            df_final_ativacoes = df_final_ativacoes.drop_duplicates(subset=['chassi'])\n",
    "\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'Duplicatas retiradas com sucesso.')\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'Falha ao retirar duplicatas. Revise o código: {e}')\n",
    "\n",
    "# TRATANDO DADOS NULOS NOS DATAFRAMES\n",
    "        try:\n",
    "            df_final_ativacoes['placa'] = df_final_ativacoes['placa'].fillna('SEM-PLACA')\n",
    "            df_final_ativacoes['chassi'] = df_final_ativacoes['chassi'].fillna('NULL')\n",
    "            df_final_ativacoes['id_placa'] = df_final_ativacoes['id_placa'].fillna(0)\n",
    "            df_final_ativacoes['id_veiculo'] = df_final_ativacoes['id_veiculo'].fillna(0)\n",
    "            df_final_ativacoes['id_carroceria'] = df_final_ativacoes['id_carroceria'].fillna(0)\n",
    "            df_final_ativacoes['matricula'] = df_final_ativacoes['matricula'].fillna(0)\n",
    "            df_final_ativacoes['conjunto'] = df_final_ativacoes['conjunto'].fillna(0)\n",
    "            df_final_ativacoes['unidade'] = df_final_ativacoes['unidade'].fillna('NULL')\n",
    "            df_final_ativacoes['consultor'] = df_final_ativacoes['consultor'].fillna('NULL')\n",
    "            df_final_ativacoes['status_beneficio'] = df_final_ativacoes['status_beneficio'].fillna('NULL')\n",
    "            df_final_ativacoes['cliente'] = df_final_ativacoes['cliente'].fillna('NULL')\n",
    "            df_final_ativacoes['data_registro'] = df_final_ativacoes['data_registro'].fillna(pd.Timestamp('1900-01-01'))\n",
    "            df_final_ativacoes['data_ativacao_beneficio'] = df_final_ativacoes['data_ativacao_beneficio'].fillna(pd.Timestamp('1900-01-01'))\n",
    "            df_final_ativacoes['suporte'] = df_final_ativacoes['suporte'].fillna('NULL')\n",
    "            df_final_ativacoes['data_filtro'] = df_final_ativacoes['data_filtro'].fillna(pd.Timestamp('1900-01-01'))\n",
    "            df_final_ativacoes['empresa'] = df_final_ativacoes['empresa'].fillna('NULL')\n",
    "            df_final_ativacoes['migration_from'] = df_final_ativacoes['migration_from'].fillna('NULL')\n",
    "\n",
    "            df_final_cancelamentos['placa'] = df_final_cancelamentos['placa'].fillna('SEM-PLACA')\n",
    "            df_final_cancelamentos['chassi'] = df_final_cancelamentos['chassi'].fillna('NULL')\n",
    "            df_final_cancelamentos['id_placa'] = df_final_cancelamentos['id_placa'].fillna(0)\n",
    "            df_final_cancelamentos['id_veiculo'] = df_final_cancelamentos['id_veiculo'].fillna(0)\n",
    "            df_final_cancelamentos['id_carroceria'] = df_final_cancelamentos['id_carroceria'].fillna(0)\n",
    "            df_final_cancelamentos['matricula'] = df_final_cancelamentos['matricula'].fillna(0)\n",
    "            df_final_cancelamentos['conjunto'] = df_final_cancelamentos['conjunto'].fillna(0)\n",
    "            df_final_cancelamentos['unidade'] = df_final_cancelamentos['unidade'].fillna('NULL')\n",
    "            df_final_cancelamentos['status'] = df_final_cancelamentos['status'].fillna('NULL')\n",
    "            df_final_cancelamentos['cliente'] = df_final_cancelamentos['cliente'].fillna('NULL')\n",
    "            df_final_cancelamentos['data'] = df_final_cancelamentos['data'].fillna(pd.Timestamp('1900-01-01'))\n",
    "            df_final_cancelamentos['data_cancelamento'] = df_final_cancelamentos['data_cancelamento'].fillna(pd.Timestamp('1900-01-01'))\n",
    "            df_final_cancelamentos['usuario_cancelamento'] = df_final_cancelamentos['usuario_cancelamento'].fillna('NULL')\n",
    "            df_final_cancelamentos['data_filtro'] = df_final_cancelamentos['data_filtro'].fillna(pd.Timestamp('1900-01-01'))\n",
    "            df_final_cancelamentos['empresa'] = df_final_cancelamentos['empresa'].fillna('NULL')\n",
    "            df_final_cancelamentos['migracao'] = df_final_cancelamentos['migracao'].fillna('NULL')\n",
    "            df_final_cancelamentos['renegociacao'] = df_final_cancelamentos['renegociacao'].fillna('NULL')\n",
    "            df_final_cancelamentos['data_substituicao'] = df_final_cancelamentos['data_substituicao'].fillna(pd.Timestamp('1900-01-01'))\n",
    "\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info('\\n Processo de Transformacao de Dados concluido com sucesso!')\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'Falha ao realizar tratamento de dados: {e}')\n",
    "     \n",
    "            return df_final_ativacoes, df_final_cancelamentos\n",
    "    \n",
    "transform = Transform()\n",
    "df_final_ativacoes, df_final_cancelamentos = transform.transforming_files()\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edf2c632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32908"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_ativacoes_ativos = df_final_ativacoes[df_final_ativacoes['status_beneficio']=='ATIVO']\n",
    "df_final_ativacoes_ativos.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf883657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>placa</th>\n",
       "      <th>chassi</th>\n",
       "      <th>id_placa</th>\n",
       "      <th>id_veiculo</th>\n",
       "      <th>id_carroceria</th>\n",
       "      <th>matricula</th>\n",
       "      <th>conjunto</th>\n",
       "      <th>unidade</th>\n",
       "      <th>consultor</th>\n",
       "      <th>status_beneficio</th>\n",
       "      <th>cliente</th>\n",
       "      <th>data_registro</th>\n",
       "      <th>data_ativacao_beneficio</th>\n",
       "      <th>suporte</th>\n",
       "      <th>data_filtro</th>\n",
       "      <th>empresa</th>\n",
       "      <th>migration_from</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31977</th>\n",
       "      <td>TAX8B12</td>\n",
       "      <td>9539J8TH9SR202365</td>\n",
       "      <td>15566883</td>\n",
       "      <td>15566883</td>\n",
       "      <td>0</td>\n",
       "      <td>5485</td>\n",
       "      <td>8355</td>\n",
       "      <td>UNIDADE LONDRINA</td>\n",
       "      <td>Gismary Orasmo</td>\n",
       "      <td>ATIVO</td>\n",
       "      <td>SANTORINI TRANSPORTE E LOGISTICA LTDA</td>\n",
       "      <td>2025-01-16</td>\n",
       "      <td>2025-01-16</td>\n",
       "      <td>Camilla Minho</td>\n",
       "      <td>2025-08-27</td>\n",
       "      <td>Viavante</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31979</th>\n",
       "      <td>TAX8B23</td>\n",
       "      <td>9539J8TH0SR203680</td>\n",
       "      <td>15566726</td>\n",
       "      <td>15566726</td>\n",
       "      <td>0</td>\n",
       "      <td>5485</td>\n",
       "      <td>8355</td>\n",
       "      <td>UNIDADE LONDRINA</td>\n",
       "      <td>Gismary Orasmo</td>\n",
       "      <td>ATIVO</td>\n",
       "      <td>SANTORINI TRANSPORTE E LOGISTICA LTDA</td>\n",
       "      <td>2025-01-16</td>\n",
       "      <td>2025-01-16</td>\n",
       "      <td>Camilla Minho</td>\n",
       "      <td>2025-08-27</td>\n",
       "      <td>Viavante</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31980</th>\n",
       "      <td>PHT5C27</td>\n",
       "      <td>97TD0N412K2001627</td>\n",
       "      <td>14227</td>\n",
       "      <td>0</td>\n",
       "      <td>14227</td>\n",
       "      <td>5488</td>\n",
       "      <td>8360</td>\n",
       "      <td>UNIDADE CUIABA</td>\n",
       "      <td>Isabella Santos</td>\n",
       "      <td>ATIVO</td>\n",
       "      <td>JAFRE RANGEL DE SOUZA</td>\n",
       "      <td>2025-01-16</td>\n",
       "      <td>2025-01-16</td>\n",
       "      <td>João Paulo Ribeiro Pinto</td>\n",
       "      <td>2025-08-27</td>\n",
       "      <td>Viavante</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31982</th>\n",
       "      <td>OKH0A38</td>\n",
       "      <td>9BVAG30C8EE824746</td>\n",
       "      <td>17376787</td>\n",
       "      <td>17376787</td>\n",
       "      <td>0</td>\n",
       "      <td>5489</td>\n",
       "      <td>18138</td>\n",
       "      <td>UNIDADE VILHENA</td>\n",
       "      <td>Vilma Girioli</td>\n",
       "      <td>ATIVO</td>\n",
       "      <td>CLEUVERSON PAZ REIS</td>\n",
       "      <td>2025-06-10</td>\n",
       "      <td>2025-06-10</td>\n",
       "      <td>Camilla Minho</td>\n",
       "      <td>2025-08-27</td>\n",
       "      <td>Viavante</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31984</th>\n",
       "      <td>RQP8I07</td>\n",
       "      <td>953998TH7NR202118</td>\n",
       "      <td>15928702</td>\n",
       "      <td>15928702</td>\n",
       "      <td>0</td>\n",
       "      <td>5493</td>\n",
       "      <td>8364</td>\n",
       "      <td>UNIDADE VILHENA</td>\n",
       "      <td>Vilma Girioli</td>\n",
       "      <td>ATIVO</td>\n",
       "      <td>JHONATAN MIRANDA PESSOA</td>\n",
       "      <td>2025-01-16</td>\n",
       "      <td>2025-01-16</td>\n",
       "      <td>VICTOR GABRIEL GOMES PICÃO</td>\n",
       "      <td>2025-08-27</td>\n",
       "      <td>Viavante</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         placa             chassi  id_placa  id_veiculo  id_carroceria  \\\n",
       "31977  TAX8B12  9539J8TH9SR202365  15566883    15566883              0   \n",
       "31979  TAX8B23  9539J8TH0SR203680  15566726    15566726              0   \n",
       "31980  PHT5C27  97TD0N412K2001627     14227           0          14227   \n",
       "31982  OKH0A38  9BVAG30C8EE824746  17376787    17376787              0   \n",
       "31984  RQP8I07  953998TH7NR202118  15928702    15928702              0   \n",
       "\n",
       "       matricula  conjunto           unidade        consultor  \\\n",
       "31977       5485      8355  UNIDADE LONDRINA   Gismary Orasmo   \n",
       "31979       5485      8355  UNIDADE LONDRINA   Gismary Orasmo   \n",
       "31980       5488      8360    UNIDADE CUIABA  Isabella Santos   \n",
       "31982       5489     18138   UNIDADE VILHENA    Vilma Girioli   \n",
       "31984       5493      8364   UNIDADE VILHENA    Vilma Girioli   \n",
       "\n",
       "      status_beneficio                                cliente data_registro  \\\n",
       "31977            ATIVO  SANTORINI TRANSPORTE E LOGISTICA LTDA    2025-01-16   \n",
       "31979            ATIVO  SANTORINI TRANSPORTE E LOGISTICA LTDA    2025-01-16   \n",
       "31980            ATIVO                  JAFRE RANGEL DE SOUZA    2025-01-16   \n",
       "31982            ATIVO                    CLEUVERSON PAZ REIS    2025-06-10   \n",
       "31984            ATIVO                JHONATAN MIRANDA PESSOA    2025-01-16   \n",
       "\n",
       "      data_ativacao_beneficio                     suporte data_filtro  \\\n",
       "31977              2025-01-16               Camilla Minho  2025-08-27   \n",
       "31979              2025-01-16               Camilla Minho  2025-08-27   \n",
       "31980              2025-01-16    João Paulo Ribeiro Pinto  2025-08-27   \n",
       "31982              2025-06-10               Camilla Minho  2025-08-27   \n",
       "31984              2025-01-16  VICTOR GABRIEL GOMES PICÃO  2025-08-27   \n",
       "\n",
       "        empresa migration_from  \n",
       "31977  Viavante           NULL  \n",
       "31979  Viavante           NULL  \n",
       "31980  Viavante           NULL  \n",
       "31982  Viavante           NULL  \n",
       "31984  Viavante           NULL  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_ativacoes_ativos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5369841f",
   "metadata": {},
   "source": [
    "transformando as planilhas excel em dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f13b0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlsx_ontem = r\"C:\\Users\\raphael.almeida\\Documents\\Processos\\placas_movimentacoes\\placas_movimentacoes_ontem.xlsx\"\n",
    "xlsx = r\"C:\\Users\\raphael.almeida\\Documents\\Processos\\placas_movimentacoes\\placas_movimentacoes.xlsx\"\n",
    "\n",
    "df_ontem = pd.read_excel(xlsx_ontem, engine='openpyxl', sheet_name= 'ATIVAÇÕES')\n",
    "df = pd.read_excel(xlsx, engine='openpyxl')\n",
    "status_filter_list = ['CANCELADO', 'CANCELADA', 'FINALIZADO', 'FINALIZADA', 'NAO RENOVADO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8de12bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ativacoes_tratado = Transform.board_status_treatment(df, df_ontem, df_conf, status_filter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fdeb2bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlsx_path = r\"C:\\Users\\raphael.almeida\\Documents\\Processos\\placas_movimentacoes\\df_tratado.xlsx\"\n",
    "df_ativacoes_tratado.to_excel(xlsx_path, engine='openpyxl', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f618f41c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ATIVO'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ativacoes_tratado['status_beneficio'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef4e566",
   "metadata": {},
   "source": [
    "# LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf9005b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-26 09:55:58,998 - INFO - \n",
      " ----------------------------------------------------------------------------------\n",
      "2025-08-26 09:55:59,000 - INFO - \n",
      " Processo de Carregamento de Dados concluido com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANDO MÓDULOS E PACOTES\n",
    "import logging\n",
    "import openpyxl\n",
    "import os\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "\n",
    "file_path = r\"C:\\Users\\raphael.almeida\\Documents\\Processos\\placas_acompanhamento\\template\\placas_movimentacoes.xlsx\"\n",
    "destination_dir = r\"C:\\Users\\raphael.almeida\\OneDrive - Grupo Unus\\analise de dados - Arquivos em excel\\Relatório de Ativações Placas\"\n",
    "destination_path = os.path.join(destination_dir, os.path.basename(file_path))\n",
    "\n",
    "with pd.ExcelWriter(destination_path, engine='openpyxl') as writer:\n",
    "    df_final_ativacoes.to_excel(writer, index=False, sheet_name='ATIVAÇÕES')\n",
    "\n",
    "\n",
    "logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "logging.info('\\n Processo de Carregamento de Dados concluido com sucesso!')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
