{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0334d0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-17 15:44:14,932 - INFO - \n",
      " ----------------------------------------------------------------------------------\n",
      "2025-09-17 15:44:14,932 - INFO - \n",
      " Executando Rotina: Movimentação de Placas\n"
     ]
    }
   ],
   "source": [
    "# EXTRACT \n",
    "import awswrangler as awr\n",
    "import logging\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import openpyxl\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Exibe mensagens a partir de INFO\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[\n",
    "        logging.StreamHandler()  # Garante logs no console\n",
    "    ]\n",
    ")\n",
    "\n",
    "logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "logging.info('\\n Executando Rotina: Movimentação de Placas')\n",
    "\n",
    "class ETL_boards:\n",
    "\n",
    "#EXTRACT\n",
    "    def __init__(self):\n",
    "        self.path = r\"C:\\Users\\raphael.almeida\\Documents\\Processos\\placas_movimentacoes\"\n",
    "        self.today = pd.Timestamp.today().date()\n",
    "        self.df_ativacoes = None\n",
    "        self.df_cancelamentos = None\n",
    "        self.df_conferencia = None\n",
    "        self.df_final_ativacoes = None\n",
    "        self.df_final_cancelamentos = None\n",
    "        if self.today.weekday() == 0:  # \n",
    "            self.yesterday = self.today - pd.Timedelta(days=3)\n",
    "        else:\n",
    "            self.yesterday = self.today - pd.Timedelta(days=1)\n",
    "       \n",
    "\n",
    "    def extract_all_ativacoes(self):\n",
    "\n",
    "        try:\n",
    "            dir_query = os.path.join(self.path, 'sql', 'all_boards_ATIVOS.sql')\n",
    "            with open(dir_query, 'r') as file:\n",
    "                query = file.read()\n",
    "            self.df_ativacoes = awr.athena.read_sql_query(query, database='silver')\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info('\\n Consulta de ativações extraída com sucesso!')\n",
    "            return self.df_ativacoes\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'\\n Falha ao extrair a consulta de ativações: {e}')\n",
    "            return None\n",
    "\n",
    "    def extract_all_cancelamentos(self):\n",
    "\n",
    "        try:\n",
    "            dir_query = os.path.join(self.path, 'sql', 'all_boards_CANCELADOS.sql')\n",
    "            with open(dir_query, 'r') as file:\n",
    "                query = file.read()\n",
    "            self.df_cancelamentos = awr.athena.read_sql_query(query, database='silver')\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info('\\n Consulta de cancelamentos extraída com sucesso!')\n",
    "            return self.df_cancelamentos\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'\\n Falha ao extrair a consulta de cancelamentos: {e}')\n",
    "            return None\n",
    "    \n",
    "    def extract_conf_boards(self):\n",
    "\n",
    "        try:\n",
    "\n",
    "            dir_query = os.path.join(self.path,'sql', 'listagem_mestra.sql')\n",
    "\n",
    "            with open(dir_query, 'r') as file:\n",
    "                query = file.read()\n",
    "\n",
    "            self.df_conferencia = awr.athena.read_sql_query(query, database='silver')\n",
    "        \n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info('\\n Relatorio conferência  - Dados Extraidos com sucesso!')\n",
    "\n",
    "            return self.df_conferencia\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'\\n Falha ao Extrair relatorio conferência: {e}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c7d0474",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-17 16:21:04,795 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:21:05,720 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:21:07,076 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:21:08,379 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:21:09,352 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:21:11,336 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:21:13,137 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:21:14,996 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:21:16,886 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:21:18,714 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:21:20,520 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:21:22,357 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:21:24,186 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:21:26,016 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:21:27,908 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:21:29,753 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:21:31,599 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:21:33,424 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:21:35,253 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:21:37,053 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:21:38,904 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:21:40,753 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:21:42,570 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:21:44,390 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:21:46,203 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:21:47,003 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:21:47,820 - INFO - Created CTAS table \"silver\".\"temp_table_267d0030ed444819b15060778d4d15be\"\n",
      "2025-09-17 16:21:47,831 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:21:48,720 - INFO - Skipping checksum validation. Response did not contain one of the following algorithms: ['crc32', 'sha1', 'sha256'].\n",
      "2025-09-17 16:21:48,735 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:21:50,057 - INFO - Skipping checksum validation. Response did not contain one of the following algorithms: ['crc32', 'sha1', 'sha256'].\n",
      "2025-09-17 16:21:50,122 - INFO - Skipping checksum validation. Response did not contain one of the following algorithms: ['crc32', 'sha1', 'sha256'].\n",
      "2025-09-17 16:21:50,171 - INFO - Skipping checksum validation. Response did not contain one of the following algorithms: ['crc32', 'sha1', 'sha256'].\n",
      "2025-09-17 16:21:50,219 - INFO - Skipping checksum validation. Response did not contain one of the following algorithms: ['crc32', 'sha1', 'sha256'].\n",
      "2025-09-17 16:21:51,946 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:21:53,258 - INFO - \n",
      " ----------------------------------------------------------------------------------\n",
      "2025-09-17 16:21:53,258 - INFO - \n",
      " Relatorio conferência  - Dados Extraidos com sucesso!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_conferencia = etl.extract_conf_boards()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9ac54cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-17 16:28:51,097 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:28:51,970 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:28:53,321 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:28:54,715 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:28:55,656 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:28:57,487 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:28:59,340 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:29:01,196 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:29:03,057 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:29:04,952 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:29:06,774 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:29:08,652 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:29:10,536 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:29:12,372 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:29:14,186 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:29:15,994 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:29:17,815 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:29:19,674 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:29:21,506 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:29:23,392 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:29:25,307 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:29:27,151 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:29:27,971 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:29:28,761 - INFO - Created CTAS table \"silver\".\"temp_table_d8a6b78fa69641f19451c91a5a5c1c2f\"\n",
      "2025-09-17 16:29:28,769 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:29:29,619 - INFO - Skipping checksum validation. Response did not contain one of the following algorithms: ['crc32', 'sha1', 'sha256'].\n",
      "2025-09-17 16:29:29,635 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:29:30,903 - INFO - Skipping checksum validation. Response did not contain one of the following algorithms: ['crc32', 'sha1', 'sha256'].\n",
      "2025-09-17 16:29:30,974 - INFO - Skipping checksum validation. Response did not contain one of the following algorithms: ['crc32', 'sha1', 'sha256'].\n",
      "2025-09-17 16:29:30,979 - INFO - Skipping checksum validation. Response did not contain one of the following algorithms: ['crc32', 'sha1', 'sha256'].\n",
      "2025-09-17 16:29:31,011 - INFO - Skipping checksum validation. Response did not contain one of the following algorithms: ['crc32', 'sha1', 'sha256'].\n",
      "2025-09-17 16:29:31,496 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-09-17 16:29:32,724 - INFO - \n",
      " ----------------------------------------------------------------------------------\n",
      "2025-09-17 16:29:32,726 - INFO - \n",
      " Consulta de ativações extraída com sucesso!\n"
     ]
    }
   ],
   "source": [
    "etl = ETL_boards()\n",
    "df_ativ_all_boards = etl.extract_all_ativacoes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6992449b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today = pd.Timestamp.today().date()\n",
    "yesterday = today - pd.Timedelta(days=1)\n",
    "\n",
    "df_ativ_all_boards_unique = df_ativ_all_boards.drop_duplicates(subset='conjunto')\n",
    "#df_ativ_all_boards_unique['data_ativacao'] = pd.to_datetime(df_ativ_all_boards_unique['data_ativacao']) \n",
    "df_ativ_all_boards_unique_yesterday = df_ativ_all_boards_unique[df_ativ_all_boards_unique['data_ativacao']==yesterday]\n",
    "df_ativ_all_boards_unique_yesterday.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eff96309",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# TRANSFORM\n",
    "def board_status_treatment( df, df_conf, status_filter_list):\n",
    "\n",
    "    try:\n",
    "        if not df.empty:\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(df.shape)\n",
    "            row_count = 0\n",
    "            for idx, row in df.iterrows():\n",
    "                row_count += 1\n",
    "                df_verification = df_conf[\n",
    "                    (df_conf['chassi'] == row['chassi']) & (df_conf['beneficio'] == row['beneficio'])\n",
    "                ].sort_values(by='data_ativacao', ascending=True)\n",
    "\n",
    "                if not df_verification.empty and len(df_verification['empresa'].values) > 1:\n",
    "                    hist_datas_ativacao = sorted(df_verification['data_ativacao_beneficio'].dropna().drop_duplicates().unique())\n",
    "\n",
    "                    if len(hist_datas_ativacao) > 1:\n",
    "                        penultimo_registro_data = hist_datas_ativacao[-2]\n",
    "                        verification_penultima_row = df_verification.loc[df_verification['data_ativacao_beneficio'] == penultimo_registro_data]\n",
    "                        \n",
    "                        if verification_penultima_row['status_beneficio'].values[0] not in status_filter_list:\n",
    "                            if verification_penultima_row['empresa'].values[0] != row['empresa']:\n",
    "                                df.at[idx, 'status_beneficio'] = 'MIGRAÇÃO'\n",
    "                                df.at[idx, 'migration_from'] = verification_penultima_row['empresa'].values[0]\n",
    "                            else:\n",
    "                                df.at[idx, 'status_beneficio'] = 'RENOVAÇÃO'\n",
    "                                df.at[idx, 'migration_from'] = 'NULL'\n",
    "                        else:\n",
    "                            # today = dt.datetime.today()\n",
    "                            # hist_datas_atualizacao = sorted(df_verification['data_atualizacao'].dropna().drop_duplicates().unique())\n",
    "                            # penultimo_registro_data_atualizacao = hist_datas_atualizacao[-2]\n",
    "                            # if today - penultimo_registro_data_atualizacao > dt.timedelta(days=30):\n",
    "                                df.at[idx, 'status_beneficio'] = 'REATIVAÇÃO'\n",
    "                                df.at[idx, 'migration_from'] = 'NULL'\n",
    "                                \n",
    "                            # else:\n",
    "                            #     if verification_penultima_row ['empresa'].values[0] != row['empresa']:\n",
    "                            #         df.at[idx, 'status_beneficio'] = 'MIGRAÇÃO'\n",
    "                            #         df.at[idx, 'migration_from'] = verification_penultima_row['empresa'].values[0]\n",
    "                            #     else:\n",
    "                            #         df.at[idx, 'status_beneficio'] = 'RENOVAÇÃO'\n",
    "                            #         df.at[idx, 'migration_from'] = 'NULL'\n",
    "                                \n",
    "                    else:\n",
    "                        df.at[idx, 'status_beneficio'] = 'ATIVO'\n",
    "                        df.at[idx, 'migration_from'] = 'NULL'\n",
    "                else:\n",
    "                    df.at[idx, 'status_beneficio'] = 'ATIVO'\n",
    "                    df.at[idx, 'migration_from'] = 'NULL'\n",
    "\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'Total de linhas processadas: {row_count}')\n",
    "\n",
    "        else:\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info('Nnehum registro de ativações para tratamento de dados. Dataframe vazio!')\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "\n",
    "        logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "        logging.info(f'Falha no tratamento de status das placas ativadas. Revise o código: {e}')\n",
    "\n",
    "    return df\n",
    "\n",
    "# DEFININDO DATAFRAMES VAZIOS \n",
    "df_final_ativacoes = pd.DataFrame()\n",
    "\n",
    "\n",
    "# TRANSFORMANDO DF_ATIV E SEGMENTANDO POR EMPRESA\n",
    "\n",
    "\n",
    "df_ativ_all_boards['data_ativacao_beneficio'] = pd.to_datetime(df_ativ_all_boards['data_ativacao_beneficio']).dt.date\n",
    "\n",
    "df_ativ_all_boards['beneficio'] = (\n",
    "    df_ativ_all_boards['beneficio']\n",
    "    .replace('REPARAÇÃO OU REPOSIÇÃO DO VEÍCULO', 'CASCO (VEÍCULO)')\n",
    "    .replace('REPARAÇÃO OU REPOSIÇÃO DO (SEMI)REBOQUE', 'CASCO (R/SR)')\n",
    "    .replace('REPARAÇÃO OU REPOSIÇÃO DO COMPLEMENTO', 'CASCO (COMPLEMENTO)')\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17a10382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today = pd.Timestamp.today().date()\n",
    "yesterday = today - pd.Timedelta(days=1)\n",
    "\n",
    "df_ativ_all_boards_unique = df_ativ_all_boards.drop_duplicates(subset='conjunto')\n",
    "#df_ativ_all_boards_unique['data_ativacao'] = pd.to_datetime(df_ativ_all_boards_unique['data_ativacao']) \n",
    "df_ativ_all_boards_unique_yesterday = df_ativ_all_boards_unique[df_ativ_all_boards_unique['data_ativacao']==yesterday]\n",
    "df_ativ_all_boards_unique_yesterday.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fa9bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-17 16:43:37,958 - INFO - \n",
      " ----------------------------------------------------------------------------------\n",
      "2025-09-17 16:43:37,960 - INFO - (354, 26)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raphael.almeida\\AppData\\Local\\Temp\\ipykernel_19952\\1146755659.py:50: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'NULL' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[idx, 'migration_from'] = 'NULL'\n",
      "2025-09-17 16:44:10,134 - INFO - \n",
      " ----------------------------------------------------------------------------------\n",
      "2025-09-17 16:44:10,136 - INFO - Total de linhas processadas: 354\n"
     ]
    }
   ],
   "source": [
    "\n",
    "today = pd.Timestamp.today().date()\n",
    "yesterday = today - pd.Timedelta(days=1)\n",
    "\n",
    "# CONCATENANDO E CRIANDO COLUNA DE MIGRAÇÃO (MIGRATION_FROM) \n",
    "df_ativ_all_boards2 = df_ativ_all_boards\n",
    "\n",
    "if not df_ativ_all_boards2.empty:\n",
    "    df_ativ_all_boards2['migration_from'] = np.nan\n",
    "\n",
    "# CRIANDO LISTA DE VERIFICAÇÃOST DE PLACAS MIGRADAS (STATUS)\n",
    "status_filter_list = ['CANCELADO', 'CANCELADA', 'FINALIZADO', 'FINALIZADA', 'NAO RENOVADO']\n",
    "\n",
    "# PEGANDO DADOS DE ATIVAÇÃO DO DIA ANTERIOR E TRATANDO\n",
    "if not df_ativ_all_boards2.empty:\n",
    "\n",
    "    df_ativos_dia_anterior = df_ativ_all_boards2[df_ativ_all_boards2['data_ativacao'] == yesterday]\n",
    "    df_ativacoes_dia_anterior_ranking_tratado = board_status_treatment(\n",
    "        df_ativos_dia_anterior, df_conferencia, status_filter_list\n",
    "    )\n",
    "    df_ativ_all_boards2 = pd.concat([df_ativacoes_dia_anterior_ranking_tratado, df_ativ_all_boards2])\n",
    "    df_ativ_all_boards2 = df_ativ_all_boards2.drop_duplicates(subset='chassi', keep='first')\n",
    "\n",
    "# DEFININDO COLUNAS QUE SERÃO UTILIZADAS NO DATAFRAME FINAL\n",
    "df_ativ_all_boards2 = df_ativ_all_boards2[[\n",
    "    'placa', 'chassi', 'id_placa', 'id_veiculo', 'id_carroceria', 'matricula', 'conjunto', 'unidade', 'consultor', 'status_beneficio', \n",
    "    'cliente', 'data_registro', 'data_ativacao', 'data_ativacao_beneficio', 'suporte', 'data_filtro', 'empresa', 'migration_from'\n",
    "]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa73eac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today = pd.Timestamp.today().date()\n",
    "yesterday = today - pd.Timedelta(days=1)\n",
    "\n",
    "df_ativ_all_boards_unique = df_ativ_all_boards2.drop_duplicates(subset='conjunto')\n",
    "#df_ativ_all_boards_unique['data_ativacao'] = pd.to_datetime(df_ativ_all_boards_unique['data_ativacao']) \n",
    "df_ativ_all_boards_unique_yesterday = df_ativ_all_boards_unique[df_ativ_all_boards_unique['data_ativacao']==yesterday]\n",
    "df_ativ_all_boards_unique_yesterday.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b11005",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TRATANDO DADOS NULOS NOS DATAFRAMES\n",
    "df_ativ_all_boards['placa'] = df_ativ_all_boards['placa'].fillna('SEM-PLACA')\n",
    "df_ativ_all_boards['chassi'] = df_ativ_all_boards['chassi'].fillna('NULL')\n",
    "df_ativ_all_boards['id_placa'] = df_ativ_all_boards['id_placa'].fillna(0)\n",
    "df_ativ_all_boards['id_veiculo'] = df_ativ_all_boards['id_veiculo'].fillna(0)\n",
    "df_ativ_all_boards['id_carroceria'] = df_ativ_all_boards['id_carroceria'].fillna(0)\n",
    "df_ativ_all_boards['matricula'] = df_ativ_all_boards['matricula'].fillna(0)\n",
    "df_ativ_all_boards['conjunto'] = df_ativ_all_boards['conjunto'].fillna(0)\n",
    "df_ativ_all_boards['unidade'] = df_ativ_all_boards['unidade'].fillna('NULL')\n",
    "df_ativ_all_boards['consultor'] = df_ativ_all_boards['consultor'].fillna('NULL')\n",
    "df_ativ_all_boards['status_beneficio'] = df_ativ_all_boards['status_beneficio'].fillna('NULL')\n",
    "df_ativ_all_boards['cliente'] = df_ativ_all_boards['cliente'].fillna('NULL')\n",
    "df_ativ_all_boards['data_registro'] = df_ativ_all_boards['data_registro'].fillna(pd.Timestamp('1900-01-01'))\n",
    "df_ativ_all_boards['data_ativacao_beneficio'] = df_ativ_all_boards['data_ativacao_beneficio'].fillna(pd.Timestamp('1900-01-01'))\n",
    "df_ativ_all_boards['suporte'] = df_ativ_all_boards['suporte'].fillna('NULL')\n",
    "df_ativ_all_boards['data_filtro'] = df_ativ_all_boards['data_filtro'].fillna(pd.Timestamp('1900-01-01'))\n",
    "df_ativ_all_boards['empresa'] = df_ativ_all_boards['empresa'].fillna('NULL')\n",
    "df_ativ_all_boards['migration_from'] = df_ativ_all_boards['migration_from'].fillna('NULL')\n",
    "\n",
    "df_final_cancelamentos['placa'] = df_final_cancelamentos['placa'].fillna('SEM-PLACA')\n",
    "df_final_cancelamentos['chassi'] = df_final_cancelamentos['chassi'].fillna('NULL')\n",
    "df_final_cancelamentos['id_placa'] = df_final_cancelamentos['id_placa'].fillna(0)\n",
    "df_final_cancelamentos['id_veiculo'] = df_final_cancelamentos['id_veiculo'].fillna(0)\n",
    "df_final_cancelamentos['id_carroceria'] = df_final_cancelamentos['id_carroceria'].fillna(0)\n",
    "df_final_cancelamentos['matricula'] = df_final_cancelamentos['matricula'].fillna(0)\n",
    "df_final_cancelamentos['conjunto'] = df_final_cancelamentos['conjunto'].fillna(0)\n",
    "df_final_cancelamentos['unidade'] = df_final_cancelamentos['unidade'].fillna('NULL')\n",
    "df_final_cancelamentos['status'] = df_final_cancelamentos['status'].fillna('NULL')\n",
    "df_final_cancelamentos['cliente'] = df_final_cancelamentos['cliente'].fillna('NULL')\n",
    "df_final_cancelamentos['data'] = df_final_cancelamentos['data'].fillna(pd.Timestamp('1900-01-01'))\n",
    "df_final_cancelamentos['data_cancelamento'] = df_final_cancelamentos['data_cancelamento'].fillna(pd.Timestamp('1900-01-01'))\n",
    "df_final_cancelamentos['usuario_cancelamento'] = df_final_cancelamentos['usuario_cancelamento'].fillna('NULL')\n",
    "df_final_cancelamentos['data_filtro'] = df_final_cancelamentos['data_filtro'].fillna(pd.Timestamp('1900-01-01'))\n",
    "df_final_cancelamentos['empresa'] = df_final_cancelamentos['empresa'].fillna('NULL')\n",
    "df_final_cancelamentos['migracao'] = df_final_cancelamentos['migracao'].fillna('NULL')\n",
    "df_final_cancelamentos['renegociacao'] = df_final_cancelamentos['renegociacao'].fillna('NULL')\n",
    "df_final_cancelamentos['data_substituicao'] = df_final_cancelamentos['data_substituicao'].fillna(pd.Timestamp('1900-01-01'))\n",
    "\n",
    "# salvar no estado do objeto para uso no LOAD\n",
    "self.df_ativ_all_boards = df_ativ_all_boards\n",
    "self.df_final_cancelamentos = df_final_cancelamentos\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280da009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD\n",
    "def loading_files(self):\n",
    "\n",
    "    try:\n",
    "        # garantir dados transformados no estado\n",
    "        if self.df_final_ativacoes is None or self.df_final_cancelamentos is None:\n",
    "            if self.df_ativacoes is None:\n",
    "                self.extract_all_ativacoes()\n",
    "            if self.df_cancelamentos is None:\n",
    "                self.extract_all_cancelamentos()\n",
    "            if self.df_conferencia is None:\n",
    "                self.extract_conf_boards()\n",
    "            self.transforming_files()\n",
    "\n",
    "        file_path = rf\"C:\\Users\\raphael.almeida\\Documents\\Processos\\placas_acompanhamento\\template\\placas_movimentacoes_{self.today}.xlsx\"\n",
    "\n",
    "        destination_dir = r\"C:\\Users\\raphael.almeida\\OneDrive - Grupo Unus\\analise de dados - Arquivos em excel\\Relatório de Ativações Placas\"\n",
    "        destination_path = os.path.join(destination_dir, os.path.basename(file_path))\n",
    "\n",
    "        destination_dir2 = r\"C:\\Users\\raphael.almeida\\Documents\\Processos\\placas_movimentacoes\\bkp_activation\"\n",
    "        destination_path2 = os.path.join(destination_dir2, os.path.basename(file_path))\n",
    "\n",
    "        os.makedirs(destination_dir, exist_ok=True)\n",
    "        os.makedirs(destination_dir2, exist_ok=True)\n",
    "\n",
    "        with pd.ExcelWriter(destination_path, engine='openpyxl') as writer:\n",
    "            self.df_final_ativacoes.to_excel(writer, index=False, sheet_name='ATIVAÇÕES')\n",
    "            self.df_final_cancelamentos.to_excel(writer, index=False, sheet_name='CANCELAMENTOS')\n",
    "\n",
    "        with pd.ExcelWriter(destination_path2, engine='openpyxl') as writer:\n",
    "            self.df_final_ativacoes.to_excel(writer, index=False, sheet_name='ATIVAÇÕES')\n",
    "            self.df_final_cancelamentos.to_excel(writer, index=False, sheet_name='CANCELAMENTOS')\n",
    "\n",
    "        logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "        logging.info('\\n Processo de Carregamento de Dados concluido com sucesso!')\n",
    "    except Exception as e:\n",
    "        logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "        logging.info(f'\\n Falha no processo de carregamento: {e}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "etl = ETL_boards()\n",
    "etl.loading_files()\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
